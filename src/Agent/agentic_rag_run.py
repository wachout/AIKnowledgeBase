"""
RAG Agentic æ™ºèƒ½ä½“è¿è¡Œæ¨¡å—ï¼ˆå¢å¼ºç‰ˆï¼‰

é‡‡ç”¨è‡ªé€‚åº”æ¡†æ¶ï¼Œå…³æ³¨æ ¸å¿ƒæ€è€ƒåºåˆ—ï¼Œéœ€è¦å¤šç§å‡è®¾ç”Ÿæˆï¼ŒåŒæ—¶ç³»ç»Ÿæ€§çš„éªŒè¯

æ™ºèƒ½ä½“æµç¨‹ï¼š
1. æ„å›¾è¯†åˆ«æ™ºèƒ½ä½“ï¼šåˆ¤æ–­æ˜¯è°ƒç”¨å·¥å…·è¿˜æ˜¯æ£€ç´¢çŸ¥è¯†åº“ï¼Œè¯†åˆ«ç”¨æˆ·æ ¸å¿ƒæ„å›¾
   a. è¯­ä¹‰æçº¯æ¶ˆé™¤æ­§ä¹‰
   b. é€»è¾‘å’Œè§„åˆ™çš„æçº¯ï¼Œæ•°ç†é€»è¾‘
2. å¦‚æœæ˜¯å·¥å…·ï¼šç›´æ¥æ‰§è¡Œå·¥å…·å¹¶è¿”å›ç»“æœ
3. å¦‚æœæ˜¯æ£€ç´¢ï¼š
   a. åˆæ­¥æŸ¥è¯¢çŸ¥è¯†åº“
   b. ç»“æœè¯„ä¼°ï¼šåˆ†ææœç´¢ç»“æœè´¨é‡
   c. å¦‚æœä¸æ»¡æ„ï¼šæ‰©å±•æœç´¢
   d. æ–‡æœ¬å†—ä½™ä¿¡æ¯èåˆæ™ºèƒ½ä½“ï¼ˆä¸ç”¨å¤§æ¨¡å‹ï¼‰
   e. è‡ªæˆ‘åæ€æ™ºèƒ½ä½“ï¼šåŠ¨æ€ç”ŸæˆSystem Prompt
   f. è°ƒåº¦æ™ºèƒ½ä½“ï¼šåˆ¤æ–­æ˜¯å¦æ‰©å±•æœç´¢ï¼ˆæœ€å¤š2æ¬¡ï¼‰
   g. Artifact å¤„ç†ï¼šåˆ†ç¦»æ¸…æ´—å†…å®¹å’ŒåŸå§‹å†…å®¹
   h. æµå¼ç”Ÿæˆå›ç­”
"""

import os
from typing import Dict, Any, Optional, List, Generator
from langchain_core.messages import BaseMessage

from Agent.AgenticRagAgent import rag_agentic_agent
from Agent.AgenticRagAgent.intent_recognition_agent import run_intent_based_search
from Agent.AgenticRagAgent.enhanced_intent_agent import EnhancedIntentAgent
from Agent.AgenticRagAgent.tool_agent import ToolAgent
from Agent.AgenticRagAgent.redundancy_fusion_agent import RedundancyFusionAgent
from Agent.AgenticRagAgent.reflection_agent import ReflectionAgent
from Agent.AgenticRagAgent.orchestrator_agent import OrchestratorAgent
from Agent.AgenticRagAgent.result_evaluator_agent import ResultEvaluatorAgent
from Agent.AgenticRagAgent.artifact_handler import ArtifactHandler
from Db.sqlite_db import cSingleSqlite


def run_rag_agentic_stream(query: str, knowledge_id: str, user_id: str, 
                          chat_history: Optional[List[BaseMessage]] = None,
                          flag: bool = True) -> Generator[Dict[str, Any], None, None]:
    """
    è¿è¡ŒRAG Agenticæ™ºèƒ½ä½“ï¼ˆå¢å¼ºç‰ˆï¼‰ï¼Œé‡‡ç”¨è‡ªé€‚åº”æ¡†æ¶è¿›è¡Œæµå¼å›ç­”ç”Ÿæˆã€‚

    å·¥ä½œæµç¨‹ï¼š
    1. æ„å›¾è¯†åˆ«æ™ºèƒ½ä½“ï¼šåˆ¤æ–­æ˜¯è°ƒç”¨å·¥å…·è¿˜æ˜¯æ£€ç´¢çŸ¥è¯†åº“ï¼Œè¯†åˆ«ç”¨æˆ·æ ¸å¿ƒæ„å›¾
       a. è¯­ä¹‰æçº¯æ¶ˆé™¤æ­§ä¹‰
       b. é€»è¾‘å’Œè§„åˆ™çš„æçº¯ï¼Œæ•°ç†é€»è¾‘
    2. å¦‚æœæ˜¯å·¥å…·ï¼šç›´æ¥æ‰§è¡Œå·¥å…·å¹¶è¿”å›ç»“æœ
    3. å¦‚æœæ˜¯æ£€ç´¢ï¼š
       a. åˆæ­¥æŸ¥è¯¢çŸ¥è¯†åº“ï¼ˆä¸‰å¼•æ“å¹¶è¡Œæœç´¢ï¼šMilvus + Elasticsearch + Graphï¼‰
       b. ç»“æœè¯„ä¼°ï¼šåˆ†ææœç´¢ç»“æœè´¨é‡
       c. æ–‡æœ¬å†—ä½™ä¿¡æ¯èåˆæ™ºèƒ½ä½“ï¼ˆä¸ç”¨å¤§æ¨¡å‹ï¼‰
       d. è‡ªæˆ‘åæ€æ™ºèƒ½ä½“ï¼šåŠ¨æ€ç”ŸæˆSystem Prompt
       e. è°ƒåº¦æ™ºèƒ½ä½“ï¼šåˆ¤æ–­æ˜¯å¦æ‰©å±•æœç´¢ï¼ˆæœ€å¤š2æ¬¡ï¼‰
       f. Artifact å¤„ç†ï¼šåˆ†ç¦»æ¸…æ´—å†…å®¹å’ŒåŸå§‹å†…å®¹
       g. æµå¼ç”Ÿæˆå›ç­”

    å‚æ•°:
        query (str): ç”¨æˆ·çš„æŸ¥è¯¢å†…å®¹ã€‚
        knowledge_id (str): çŸ¥è¯†åº“IDã€‚
        user_id (str): ç”¨æˆ·IDã€‚
        chat_history (Optional[List[BaseMessage]]): èŠå¤©å†å²ï¼ˆå¯é€‰ï¼‰ã€‚
        flag (bool): æƒé™æ ‡å¿—ï¼ŒæŒ‡ç¤ºæ˜¯å¦è¿›è¡Œæ„å›¾è¯†åˆ«ã€‚

    è¿”å›:
        Generator[Dict[str, Any], None, None]: å“åº”æµç”Ÿæˆå™¨ã€‚
    """
    
    # åˆå§‹åŒ–ç»„ä»¶
    enhanced_intent_agent = EnhancedIntentAgent()
    tool_agent = ToolAgent()
    redundancy_fusion_agent = RedundancyFusionAgent()
    reflection_agent = ReflectionAgent()
    orchestrator_agent = OrchestratorAgent(max_expansions=2)
    evaluator_agent = ResultEvaluatorAgent()
    artifact_handler = ArtifactHandler()
    
    # æ­¥éª¤1: è·å–çŸ¥è¯†åº“å…ƒæ•°æ®
    print("ğŸ“š æ­¥éª¤1: è·å–çŸ¥è¯†åº“å…ƒæ•°æ®...")
    knowledge_description_d = cSingleSqlite.search_knowledge_base_by_knowledge_id(knowledge_id)
    knowledge_description = knowledge_description_d.get("description", "çŸ¥è¯†åº“æœªæè¿°")
    
    # è½¬æ¢èŠå¤©å†å²æ ¼å¼
    history_list = None
    if chat_history:
        history_list = [
            {"role": "user" if hasattr(msg, "type") and msg.type == "human" else "assistant",
             "content": msg.content if hasattr(msg, "content") else str(msg)}
            for msg in chat_history[-5:]  # åªä½¿ç”¨æœ€è¿‘5è½®
        ]
    
    # æ­¥éª¤2: å¢å¼ºçš„æ„å›¾è¯†åˆ«æ™ºèƒ½ä½“
    print("ğŸ¯ æ­¥éª¤2: å¢å¼ºçš„æ„å›¾è¯†åˆ«ï¼ˆè¯­ä¹‰æçº¯ + é€»è¾‘æçº¯ï¼‰...")
    intent_result = enhanced_intent_agent.analyze_intent(
        query=query,
        knowledge_description=knowledge_description,
        chat_history=history_list
    )
    
    action = intent_result.get("action", "retrieve")
    core_intent = intent_result.get("core_intent", "")
    semantic_purified_query = intent_result.get("semantic_purified_query", query)
    
    # å’¨è¯¢æœ¬æºè¯†åˆ«ç»“æœ
    consultation_root_cause = intent_result.get("consultation_root_cause", "")
    consultation_essence = intent_result.get("consultation_essence", "")
    consultation_core_issue = intent_result.get("consultation_core_issue", "")
    consultation_source = intent_result.get("consultation_source", "")
    
    print(f"âœ… æ„å›¾è¯†åˆ«ç»“æœ: {action}")
    print(f"âœ… æ ¸å¿ƒæ„å›¾: {core_intent}")
    print(f"âœ… è¯­ä¹‰æçº¯æŸ¥è¯¢: {semantic_purified_query}")
    print(f"ğŸ” å’¨è¯¢æœ¬æºè¯†åˆ«:")
    print(f"   - æ ¹æœ¬åŸå› : {consultation_root_cause}")
    print(f"   - æœ¬è´¨æ„å›¾: {consultation_essence}")
    print(f"   - æ ¸å¿ƒé—®é¢˜: {consultation_core_issue}")
    print(f"   - å’¨è¯¢æ ¹æº: {consultation_source}")
    
    # æ­¥éª¤3: æ ¹æ®å†³ç­–æ‰§è¡Œç›¸åº”è¡ŒåŠ¨
    if action == "tool":
        # å·¥å…·è°ƒç”¨è·¯å¾„
        print("ğŸ”§ æ‰§è¡Œå·¥å…·è°ƒç”¨...")
        tool_name = intent_result.get("tool_name", "")
        print(f"ğŸ› ï¸ å·¥å…·åç§°: {tool_name}")
        
        # ä½¿ç”¨å·¥å…·æ™ºèƒ½ä½“æ ¹æ® intent_result æ‰§è¡Œå·¥å…·
        tool_execution_result = tool_agent.execute_tool_by_intent(
            intent_result=intent_result,
            query=query,
            knowledge_id=knowledge_id
        )
        
        if tool_execution_result.get("success", False):
            # å·¥å…·æ‰§è¡ŒæˆåŠŸï¼Œæµå¼è¾“å‡ºç»“æœ
            formatted_content = tool_execution_result.get("formatted_content", "")
            tool_name_executed = tool_execution_result.get("tool_name", tool_name)
            
            print(f"âœ… å·¥å…· {tool_name_executed} æ‰§è¡ŒæˆåŠŸ")
            
            # æµå¼è¾“å‡ºå·¥å…·ç»“æœ
            chunk = create_chunk(f"tool_result_{hash(query)}", int(os.times()[4]), 
                               default_content=formatted_content, _type="text", 
                               intent_analysis=intent_result, search_results="", finish_reason=None)
            yield chunk
            
            # å‘é€ç»“æŸæ ‡è®°
            chunk = create_chunk(f"tool_end_{hash(query)}", int(os.times()[4]), 
                               default_content="", _type="text", 
                               intent_analysis=intent_result, search_results="", finish_reason="stop")
            yield chunk
            return
        else:
            # å·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œè½¬ä¸ºæ£€ç´¢æ¨¡å¼
            error_msg = tool_execution_result.get("error", "æœªçŸ¥é”™è¯¯")
            print(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {error_msg}ï¼Œè½¬ä¸ºæ£€ç´¢æ¨¡å¼")
            action = "retrieve"
    
    # æ£€ç´¢è·¯å¾„ï¼šåˆæ­¥æŸ¥è¯¢çŸ¥è¯†åº“
    print("ğŸ” æ­¥éª¤3: åˆæ­¥æŸ¥è¯¢çŸ¥è¯†åº“...")
    # ä½¿ç”¨queryå’Œintent_resultè¿›è¡Œè¯­ä¹‰æœç´¢
    print(f"ğŸ” åŸå§‹æŸ¥è¯¢: {query}")
    print(f"ğŸ” è¯­ä¹‰æçº¯æŸ¥è¯¢: {semantic_purified_query}")
    intent_search_result = run_intent_based_search(
        query=query, 
        knowledge_id=knowledge_id, 
        user_id=user_id, 
        flag=flag, 
        intent_result=intent_result  # ä¼ å…¥å¢å¼ºçš„æ„å›¾è¯†åˆ«ç»“æœ
    )
    
    initial_results = intent_search_result.get("search_results", [])
    # åˆå¹¶å¢å¼ºæ„å›¾è¯†åˆ«çš„ç»“æœ
    intent_analysis = {
        **intent_result,
        **intent_search_result.get("intent_analysis", {})
    }
    
    print(f"ğŸ“Š åˆæ­¥æœç´¢è·å¾— {len(initial_results)} ä¸ªç»“æœ")
    
    # æ­¥éª¤4: ç»“æœè¯„ä¼°
    print("ğŸ“ˆ æ­¥éª¤4: è¯„ä¼°æœç´¢ç»“æœè´¨é‡...")
    evaluation = evaluator_agent.evaluate_results(
        query=query,
        search_results=initial_results,
        intent_analysis=intent_analysis
    )
    
    print(f"âœ… è´¨é‡è¯„åˆ†: {evaluation.get('quality_score', 0):.2f}")
    print(f"âœ… æ˜¯å¦æ»¡æ„: {evaluation.get('is_satisfactory', False)}")
    
    # æ­¥éª¤5: æ–‡æœ¬å†—ä½™ä¿¡æ¯èåˆæ™ºèƒ½ä½“ï¼ˆä¸ç”¨å¤§æ¨¡å‹ï¼‰
    print("ğŸ”— æ­¥éª¤5: æ–‡æœ¬å†—ä½™ä¿¡æ¯èåˆï¼ˆæ‹†å¥ã€æ‰¾å…³ç³»ã€æ¶æ¡¥æ¢ï¼‰...")
    fused_result = redundancy_fusion_agent.fuse_redundant_information(initial_results)
    
    if fused_result.get("success"):
        print(f"âœ… èåˆå®Œæˆï¼š{len(fused_result.get('core_sentences', []))} ä¸ªæ ¸å¿ƒå¥å­")
        print(f"âœ… ä¸»é¢˜æ¡¥æ¢ï¼š{len(fused_result.get('topic_bridges', []))} ä¸ª")
    
    # æ­¥éª¤6: è‡ªæˆ‘åæ€æ™ºèƒ½ä½“ + è°ƒåº¦æ™ºèƒ½ä½“ï¼ˆå¾ªç¯æœ€å¤š2æ¬¡ï¼‰
    print("ğŸ¤” æ­¥éª¤6: è‡ªæˆ‘åæ€ + è°ƒåº¦æ‰©å±•æœç´¢...")
    final_results = initial_results
    expansion_count = 0
    system_prompt = ""
    
    while expansion_count < 2:
        # è‡ªæˆ‘åæ€
        reflection_result = reflection_agent.reflect_and_generate_prompt(
            query=query,
            fused_content=fused_result,
            search_results=final_results,
            intent_analysis=intent_analysis
        )
        
        if reflection_result.get("success"):
            system_prompt = reflection_result.get("system_prompt", "")
            print(f"âœ… åæ€å®Œæˆï¼Œç”ŸæˆSystem Prompt: {len(system_prompt)} å­—ç¬¦")
        
        # è°ƒåº¦æ™ºèƒ½ä½“åˆ¤æ–­æ˜¯å¦æ‰©å±•
        expansion_decision = orchestrator_agent.should_expand_search(
            reflection_result=reflection_result,
            expansion_count=expansion_count
        )
        
        if not expansion_decision.get("should_expand", False):
            print(f"âœ… è°ƒåº¦å†³ç­–ï¼šä¸éœ€è¦æ‰©å±•æœç´¢ï¼ˆ{expansion_decision.get('reason', '')}ï¼‰")
            break
        
        # æ‰§è¡Œæ‰©å±•æœç´¢
        expansion_count += 1
        print(f"ğŸš€ æ‰§è¡Œç¬¬ {expansion_count} æ¬¡æ‰©å±•æœç´¢...")
        
        suggested_queries = expansion_decision.get("suggested_queries", [])
        expanded_results = []
        
        # å°† reflection_result è½¬æ¢ä¸ºæ„å›¾è¯†åˆ«ç»“æœæ ¼å¼ï¼Œç”¨äºæŒ‡å¯¼æ‰©å±•æœç´¢
        reflection_intent_result = None
        if reflection_result.get("success"):
            # ä» reflection_result ä¸­æå–ä¿¡æ¯æ„å»ºæ„å›¾è¯†åˆ«ç»“æœ
            missing_info = reflection_result.get("missing_information", [])
            reasoning = reflection_result.get("reasoning", "")
            
            # å°†ç¼ºå¤±ä¿¡æ¯è½¬æ¢ä¸ºå®ä½“åˆ—è¡¨ï¼ˆç”¨äºæœç´¢ï¼‰
            entities = []
            if isinstance(missing_info, list):
                entities = [str(item) for item in missing_info if item]
            
            reflection_intent_result = {
                "semantic_purified_query": reflection_result.get("suggested_queries", [""])[0] if reflection_result.get("suggested_queries") else query,
                "core_intent": f"æ‰©å±•æœç´¢: {reasoning[:100] if reasoning else 'åŸºäºåæ€ç»“æœè¿›è¡Œæ‰©å±•æœç´¢'}",
                "entities": entities,  # ä½¿ç”¨ç¼ºå¤±ä¿¡æ¯ä½œä¸ºå®ä½“
                "relationships": [],
                "attributes": [],
                "missing_information": missing_info,
                "reasoning": reasoning,
                "needs_expansion": reflection_result.get("needs_expansion", True)
            }
            print(f"ğŸ” ä½¿ç”¨åæ€ç»“æœæŒ‡å¯¼æ‰©å±•æœç´¢:")
            print(f"   - åæ€ç†ç”±: {reasoning[:100] if reasoning else 'æ— '}")
            print(f"   - ç¼ºå¤±ä¿¡æ¯: {missing_info[:3] if missing_info else 'æ— '}")
            print(f"   - å®ä½“æå–: {entities[:3] if entities else 'æ— '}")
        
        for expanded_query in suggested_queries:
            print(f"  - æ‰©å±•æœç´¢: {expanded_query[:50]}...")
            # ä¸ºæ¯ä¸ªæ‰©å±•æŸ¥è¯¢æ„å»ºç‰¹å®šçš„æ„å›¾ç»“æœ
            expanded_intent_result = None
            if reflection_intent_result:
                expanded_intent_result = {
                    **reflection_intent_result,
                    "semantic_purified_query": expanded_query,  # ä½¿ç”¨æ‰©å±•æŸ¥è¯¢ä½œä¸ºè¯­ä¹‰æçº¯æŸ¥è¯¢
                    "core_intent": f"æ‰©å±•æœç´¢: {expanded_query}"
                }
            
            # ä½¿ç”¨ expanded_query å’Œ reflection_result è¿›è¡ŒçŸ¥è¯†åº“æœç´¢
            expanded_result = run_intent_based_search(
                query=expanded_query,
                knowledge_id=knowledge_id,
                user_id=user_id,
                flag=flag,
                intent_result=expanded_intent_result  # ä¼ å…¥åŸºäºåæ€ç»“æœçš„æ„å›¾è¯†åˆ«ç»“æœ
            )
            expanded_results.extend(expanded_result.get("search_results", []))
        
        # åˆå¹¶ç»“æœ
        final_results = final_results + expanded_results
        print(f"ğŸ“ˆ æ‰©å±•åå…±è·å¾— {len(final_results)} ä¸ªç»“æœ")
        
        # é‡æ–°èåˆä¿¡æ¯
        fused_result = redundancy_fusion_agent.fuse_redundant_information(final_results)
    
    # æ­¥éª¤7: Artifact å¤„ç†
    print("ğŸ¨ æ­¥éª¤7: å¤„ç† Artifact...")
    artifact_data = artifact_handler.process_search_results(final_results)
    cleaned_content = artifact_data["cleaned_content"]
    artifacts = artifact_data["artifacts"]
    
    # å¦‚æœæ²¡æœ‰ç”ŸæˆSystem Promptï¼Œä½¿ç”¨èåˆåçš„å†…å®¹
    if not system_prompt:
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}
æ ¸å¿ƒæ„å›¾ï¼š{core_intent}

è¯·ä½¿ç”¨ä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š
{cleaned_content}

è¦æ±‚ï¼š
1. å‡†ç¡®ç†è§£ç”¨æˆ·çš„æ ¸å¿ƒæ„å›¾
2. åŸºäºæä¾›çš„ä¿¡æ¯è¿›è¡Œå›ç­”
3. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯´æ˜"""
    
    # æ­¥éª¤8: æ„å»ºæœç´¢ç»“æœæ–‡æœ¬ï¼ˆç”¨äºRAGï¼‰
    # ä¼˜å…ˆä½¿ç”¨èåˆåçš„å†…å®¹
    search_content = fused_result.get("fused_content", cleaned_content) if fused_result.get("success") else cleaned_content
    
    # æ­¥éª¤9: è°ƒç”¨RAGæµå¼å¤„ç†ï¼ˆä¼ å…¥åŠ¨æ€System Promptï¼‰
    print("ğŸ¯ æ­¥éª¤9: æµå¼ç”Ÿæˆå›ç­”...")
    chunk_count = 0
    
    # å…ˆå‘é€ Artifact ä¿¡æ¯ï¼ˆç»™ç”¨æˆ·çœ‹ï¼‰
    artifacts_chunk = create_chunk(
        f"artifacts_{hash(query)}",
        int(os.times()[4]),
        default_content="",
        _type="artifacts",
        intent_analysis=intent_analysis,
        search_results=artifact_handler.format_artifacts_for_frontend(artifacts),
        finish_reason=None
    )
    yield artifacts_chunk
    
    # ç„¶åæµå¼ç”Ÿæˆå›ç­”
    for chunk in rag_agentic_agent.rag_stream(
        query=query,
        intent_analysis=intent_analysis,
        search_results=final_results,
        search_content=search_content,
        system_prompt=system_prompt  # ä¼ å…¥åŠ¨æ€ç”Ÿæˆçš„System Prompt
    ):
        chunk_count += 1
        yield chunk
    
    # å¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½•chunkï¼Œç”Ÿæˆé»˜è®¤å“åº”
    if chunk_count == 0:
        print("âš ï¸ RAGæµå¼å¤„ç†æ²¡æœ‰äº§ç”Ÿä»»ä½•chunkï¼Œç”Ÿæˆé»˜è®¤å“åº”")
        default_content = ""
        if not final_results:
            default_content = "æŠ±æ­‰ï¼ŒåŸºäºæ‚¨çš„æŸ¥è¯¢æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·å°è¯•é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ï¼Œæˆ–è€…æ£€æŸ¥çŸ¥è¯†åº“ä¸­æ˜¯å¦æœ‰ç›¸å…³å†…å®¹ã€‚"
        else:
            default_content = f"å·²æ‰¾åˆ° {len(final_results)} æ¡ç›¸å…³ä¿¡æ¯ï¼Œä½†ç”Ÿæˆå›ç­”æ—¶å‡ºç°é—®é¢˜ã€‚è¯·ç¨åé‡è¯•ã€‚"
        
        _id = f"rag_default_{hash(query)}"
        chunk = create_chunk(_id, int(os.times()[4]), default_content, 
                           intent_analysis=intent_analysis, 
                           search_results=final_results,
                           finish_reason="stop")
        yield chunk


def create_chunk(_id, _time, default_content="", _type="text", 
                 intent_analysis="", search_results="",
                 finish_reason="stop"):
    """åˆ›å»ºchunkå¯¹è±¡"""
    chunk_data = {
        "id": _id,
        "object": "chat.completion.chunk",
        "created": int(os.times()[4]),
        "model": "rag-agentic-model",
        "choices": [{
            "index": 0,
            "delta": {
                "content": default_content,
                "type": _type,
            },
            "finish_reason": finish_reason
        }]
    }
    
    # æ·»åŠ é¢å¤–å­—æ®µ
    if intent_analysis:
        chunk_data["choices"][0]["delta"]["intent_analysis"] = intent_analysis
    if search_results:
        if isinstance(search_results, list):
            chunk_data["choices"][0]["delta"]["search_results_count"] = len(search_results)
            chunk_data["choices"][0]["delta"]["artifacts"] = search_results
        else:
            chunk_data["choices"][0]["delta"]["search_results"] = search_results
    
    return chunk_data

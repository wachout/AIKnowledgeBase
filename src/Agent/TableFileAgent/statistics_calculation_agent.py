# -*- coding:utf-8 -*-
"""
æ•°ç†ç»Ÿè®¡æ™ºèƒ½ä½“
è°ƒç”¨æ•°ç†ç»Ÿè®¡æ™ºèƒ½ä½“ï¼Œé€»è¾‘è®¡ç®—è§„åˆ™ï¼Œå¼€å§‹è®¡ç®—æ•°æ®
è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡åï¼Œç»“åˆä¸šåŠ¡è¯­ä¹‰ç”Ÿæˆ ECharts ç»“æ„æ•°æ®æ–¹ä¾¿å±•ç¤º
"""

import os
import json
import logging
from typing import Dict, Any, List
from Math.statistics import StatisticsCalculator
from Agent.echarts_run import query_echarts

logger = logging.getLogger(__name__)


class StatisticsCalculationAgent:
    """æ•°ç†ç»Ÿè®¡æ™ºèƒ½ä½“ï¼šæ‰§è¡Œç»Ÿè®¡è®¡ç®—ï¼Œå¹¶ç”Ÿæˆ ECharts ç»“æ„æ•°æ®"""
    
    def __init__(self):
        # ğŸ¯ ç»Ÿä¸€ç®¡ç†ï¼šé€šè¿‡ echarts_run.py è°ƒç”¨ echarts æ™ºèƒ½ä½“
        # ä¸éœ€è¦åˆå§‹åŒ– echarts_agentï¼Œç›´æ¥ä½¿ç”¨ echarts_run.py ä¸­çš„å‡½æ•°
        pass
    
    def calculate(self, file_info: Dict[str, Any], 
                  statistics_plan: Dict[str, Any],
                  file_understanding_result: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œç»Ÿè®¡è®¡ç®—ï¼Œå¹¶ç”Ÿæˆ ECharts ç»“æ„æ•°æ®
        
        Args:
            file_info: æ–‡ä»¶ä¿¡æ¯
            statistics_plan: ç»Ÿè®¡è®¡ç®—è§„åˆ’
            file_understanding_result: æ–‡ä»¶ç†è§£ç»“æœï¼ˆç”¨äºä¸šåŠ¡è¯­ä¹‰ï¼‰
            
        Returns:
            ç»Ÿè®¡è®¡ç®—ç»“æœï¼ŒåŒ…å«ç»Ÿè®¡æŒ‡æ ‡å’Œ ECharts ç»“æ„æ•°æ®
        """
        try:
            result = {
                "calculations": {},
                "echarts_structures": {}  # æ–°å¢ï¼šå­˜å‚¨æ¯ä¸ªå·¥ä½œè¡¨çš„ ECharts ç»“æ„
            }
            
            # ä¸ºæ¯ä¸ªå·¥ä½œè¡¨åˆ›å»ºä¸´æ—¶CSVæ–‡ä»¶å¹¶è®¡ç®—ç»Ÿè®¡
            for sheet_name, df in file_info.get("data", {}).items():
                # åˆ›å»ºä¸´æ—¶CSVæ–‡ä»¶
                temp_csv_path = self._save_to_temp_csv(df, file_info["file_path"], sheet_name)
                
                # è·å–è¯¥å·¥ä½œè¡¨çš„è§„åˆ’
                sheet_plan = self._find_sheet_plan(sheet_name, statistics_plan)
                
                if sheet_plan:
                    # æ‰§è¡Œç»Ÿè®¡è®¡ç®—
                    sheet_result = self._calculate_for_sheet(
                        temp_csv_path, df, sheet_plan
                    )
                    result["calculations"][sheet_name] = sheet_result
                else:
                    # å¦‚æœæ²¡æœ‰è§„åˆ’ï¼Œæ‰§è¡Œé»˜è®¤ç»Ÿè®¡
                    sheet_result = self._calculate_default_statistics(temp_csv_path, df)
                    result["calculations"][sheet_name] = sheet_result
                
                # ğŸ¯ ç»“åˆä¸šåŠ¡è¯­ä¹‰ç”Ÿæˆ ECharts ç»“æ„æ•°æ®ï¼ˆåŸºäºç»Ÿè®¡æŒ‡æ ‡ï¼Œä¸æ˜¯åŸå§‹æ•°æ®ï¼‰
                if sheet_result and not sheet_result.get("error"):
                    echarts_structures = self._generate_echarts_from_indicators(
                        sheet_name,
                        sheet_result,
                        file_understanding_result,
                        file_info
                    )
                    if echarts_structures:
                        result["echarts_structures"][sheet_name] = echarts_structures
            
            logger.info(f"âœ… ç»Ÿè®¡è®¡ç®—å®Œæˆï¼Œå…±è®¡ç®— {len(result['calculations'])} ä¸ªå·¥ä½œè¡¨")
            logger.info(f"âœ… ç”Ÿæˆ ECharts ç»“æ„ {len(result.get('echarts_structures', {}))} ä¸ªå·¥ä½œè¡¨")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ç»Ÿè®¡è®¡ç®—å¤±è´¥: {e}")
            raise
    
    def _save_to_temp_csv(self, df, original_file_path: str, sheet_name: str) -> str:
        """ä¿å­˜DataFrameåˆ°ä¸´æ—¶CSVæ–‡ä»¶"""
        import tempfile
        
        temp_dir = "conf/tmp/table_analysis"
        os.makedirs(temp_dir, exist_ok=True)
        
        base_name = os.path.splitext(os.path.basename(original_file_path))[0]
        temp_csv_path = os.path.join(temp_dir, f"{base_name}_{sheet_name}_temp.csv")
        
        df.to_csv(temp_csv_path, index=False, encoding='utf-8')
        return temp_csv_path
    
    def _find_sheet_plan(self, sheet_name: str, statistics_plan: Dict[str, Any]) -> Dict[str, Any]:
        """æŸ¥æ‰¾å·¥ä½œè¡¨çš„è§„åˆ’"""
        for plan in statistics_plan.get("statistics_plan", {}).get("sheets_plans", []):
            if plan.get("sheet_name") == sheet_name:
                return plan
        return None
    
    def _calculate_for_sheet(self, csv_path: str, df, sheet_plan: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®è§„åˆ’æ‰§è¡Œç»Ÿè®¡è®¡ç®—"""
        result = {}
        
        try:
            # åˆå§‹åŒ–ç»Ÿè®¡è®¡ç®—å™¨
            calculator = StatisticsCalculator(csv_path)
            
            # è·å–åˆ—ç±»å‹
            columns_types = []
            for col in df.columns:
                if df[col].dtype in ['int64', 'float64']:
                    columns_types.append('numeric')
                else:
                    columns_types.append('text')
            
            # æ‰§è¡Œæ‰€æœ‰ç»Ÿè®¡è®¡ç®—
            all_stats = calculator.calculate_all_statistics(columns_types)
            
            # æ ¹æ®è§„åˆ’ç­›é€‰å’Œæ•´ç†ç»“æœ
            for calc in sheet_plan.get("calculations", []):
                calc_type = calc.get("calculation_type", "")
                target_cols = calc.get("target_columns", [])
                
                # æ ¹æ®è®¡ç®—ç±»å‹æå–ç›¸åº”çš„ç»Ÿè®¡ç»“æœ
                if "æè¿°æ€§ç»Ÿè®¡" in calc_type or "descriptive" in calc_type.lower():
                    result["descriptive_statistics"] = all_stats.get("descriptive_statistics", {})
                elif "ç›¸å…³æ€§" in calc_type or "correlation" in calc_type.lower():
                    result["correlation_analysis"] = all_stats.get("correlation_analysis", {})
                elif "é¢‘ç‡" in calc_type or "frequency" in calc_type.lower():
                    result["frequency_analysis"] = all_stats.get("frequency_analysis", {})
                elif "åˆ†ç»„" in calc_type or "grouped" in calc_type.lower():
                    result["grouped_statistics"] = all_stats.get("grouped_statistics", {})
                elif "åˆ†å¸ƒ" in calc_type or "distribution" in calc_type.lower():
                    result["distribution_analysis"] = all_stats.get("distribution_analysis", {})
                elif "è¶‹åŠ¿" in calc_type or "trend" in calc_type.lower():
                    result["trend_analysis"] = all_stats.get("trend_analysis", {})
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›æ‰€æœ‰ç»Ÿè®¡ç»“æœ
            if not result:
                result = all_stats
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œè¡¨ç»Ÿè®¡è®¡ç®—å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _calculate_default_statistics(self, csv_path: str, df) -> Dict[str, Any]:
        """æ‰§è¡Œé»˜è®¤ç»Ÿè®¡è®¡ç®—"""
        try:
            calculator = StatisticsCalculator(csv_path)
            columns_types = ['numeric' if df[col].dtype in ['int64', 'float64'] else 'text' 
                           for col in df.columns]
            return calculator.calculate_all_statistics(columns_types)
        except Exception as e:
            logger.error(f"âŒ é»˜è®¤ç»Ÿè®¡è®¡ç®—å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _generate_echarts_from_indicators(self,
                                         sheet_name: str,
                                         statistics_indicators: Dict[str, Any],
                                         file_understanding_result: Dict[str, Any],
                                         file_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        åŸºäºç»Ÿè®¡æŒ‡æ ‡ï¼ˆä¸æ˜¯åŸå§‹æ•°æ®ï¼‰ç»“åˆä¸šåŠ¡è¯­ä¹‰ç”Ÿæˆ ECharts ç»“æ„æ•°æ®
        
        Args:
            sheet_name: å·¥ä½œè¡¨åç§°
            statistics_indicators: ç»Ÿè®¡æŒ‡æ ‡ï¼ˆæè¿°æ€§ç»Ÿè®¡ã€ç›¸å…³æ€§åˆ†æç­‰ï¼‰
            file_understanding_result: æ–‡ä»¶ç†è§£ç»“æœï¼ˆä¸šåŠ¡è¯­ä¹‰ï¼‰
            file_info: æ–‡ä»¶ä¿¡æ¯
            
        Returns:
            ECharts ç»“æ„æ•°æ®åˆ—è¡¨
        """
        try:
            echarts_structures = []
            
            # ğŸ¯ ç²¾ç®€ç»Ÿè®¡æŒ‡æ ‡ï¼šåªä¿ç•™ç”¨äºç”Ÿæˆå›¾è¡¨çš„å…³é”®ä¿¡æ¯
            # ä¸åŒ…å«å®Œæ•´çš„ç›¸å…³æ€§çŸ©é˜µã€å®Œæ•´é¢‘ç‡åˆ†å¸ƒç­‰å¤§æ•°æ®
            simplified_indicators = self._simplify_indicators(statistics_indicators)
            
            # ğŸ¯ éªŒè¯ï¼šç¡®è®¤ä¸åŒ…å«å®Œæ•´æ•°æ®çŸ©é˜µ
            if "correlation_analysis" in simplified_indicators:
                corr = simplified_indicators["correlation_analysis"]
                if isinstance(corr, dict) and "correlation_matrix" in corr:
                    logger.error("âŒ é”™è¯¯ï¼šç²¾ç®€åçš„æŒ‡æ ‡ä»åŒ…å« correlation_matrixï¼")
                    corr.pop("correlation_matrix", None)
                    logger.warning("âš ï¸ å·²å¼ºåˆ¶ç§»é™¤ correlation_matrix")
            
            if "frequency_analysis" in simplified_indicators:
                freq = simplified_indicators["frequency_analysis"]
                for col_name, freq_data in freq.items():
                    if isinstance(freq_data, dict) and "frequency" in freq_data:
                        logger.error(f"âŒ é”™è¯¯ï¼šç²¾ç®€åçš„æŒ‡æ ‡ä»åŒ…å«å®Œæ•´ frequency å­—å…¸ï¼åˆ—: {col_name}")
                        freq_data.pop("frequency", None)
                        logger.warning(f"âš ï¸ å·²å¼ºåˆ¶ç§»é™¤å®Œæ•´ frequency å­—å…¸")
            
            indicators_str = json.dumps(simplified_indicators, ensure_ascii=False, default=str)
            
            # ğŸ¯ æœ€ç»ˆéªŒè¯ï¼šç¡®è®¤åºåˆ—åŒ–åçš„æ•°æ®ä¸åŒ…å« correlation_matrix
            if "correlation_matrix" in indicators_str:
                logger.error("âŒ ä¸¥é‡é”™è¯¯ï¼šåºåˆ—åŒ–åçš„æŒ‡æ ‡ä»åŒ…å« correlation_matrixï¼")
                # å°è¯•ç§»é™¤
                indicators_dict = json.loads(indicators_str)
                if "correlation_analysis" in indicators_dict:
                    indicators_dict["correlation_analysis"].pop("correlation_matrix", None)
                indicators_str = json.dumps(indicators_dict, ensure_ascii=False, default=str)
                logger.warning("âš ï¸ å·²ä»åºåˆ—åŒ–æ•°æ®ä¸­ç§»é™¤ correlation_matrix")
            
            logger.info(f"âœ… æ­¥éª¤4ç²¾ç®€åçš„æŒ‡æ ‡é•¿åº¦: {len(indicators_str)} å­—ç¬¦ï¼Œä¸åŒ…å« correlation_matrix")
            
            # å¦‚æœä»ç„¶å¤ªå¤§ï¼Œè¿›ä¸€æ­¥ç²¾ç®€
            if len(indicators_str) > 50000:  # 50KB
                logger.warning(f"âš ï¸ ç»Ÿè®¡æŒ‡æ ‡æ•°æ®ä»ç„¶è¿‡å¤§ï¼ˆ{len(indicators_str)}å­—ç¬¦ï¼‰ï¼Œè¿›è¡Œè¿›ä¸€æ­¥ç²¾ç®€")
                # åªä¿ç•™æœ€å…³é”®çš„æŒ‡æ ‡
                ultra_simplified = {}
                # æè¿°æ€§ç»Ÿè®¡ï¼šåªä¿ç•™å…³é”®æŒ‡æ ‡
                if "descriptive_statistics" in simplified_indicators:
                    desc = simplified_indicators["descriptive_statistics"]
                    ultra_simplified["descriptive_statistics"] = {
                        col: {k: v for k, v in stats.items() if k in ["mean", "median", "std", "min", "max"]}
                        for col, stats in list(desc.items())[:10]  # åªä¿ç•™å‰10åˆ—
                    }
                # ç›¸å…³æ€§åˆ†æï¼šåªä¿ç•™å¼ºç›¸å…³å…³ç³»
                if "correlation_analysis" in simplified_indicators:
                    corr = simplified_indicators["correlation_analysis"]
                    if isinstance(corr, dict) and corr.get("strong_correlations"):
                        ultra_simplified["correlation_analysis"] = {
                            "strong_correlations": corr["strong_correlations"][:10]  # åªä¿ç•™å‰10ä¸ª
                        }
                # é¢‘ç‡åˆ†æï¼šåªä¿ç•™ top_10 æ±‡æ€»
                if "frequency_analysis" in simplified_indicators:
                    freq = simplified_indicators["frequency_analysis"]
                    ultra_simplified["frequency_analysis"] = {
                        col: {
                            "unique_count": stats.get("unique_count"),
                            "top_10": stats.get("top_10", {})
                        }
                        for col, stats in list(freq.items())[:5]  # åªä¿ç•™å‰5åˆ—
                    }
                simplified_indicators = ultra_simplified
                indicators_str = json.dumps(simplified_indicators, ensure_ascii=False, default=str)
                logger.info(f"âœ… è¿›ä¸€æ­¥ç²¾ç®€åé•¿åº¦: {len(indicators_str)} å­—ç¬¦")
            
            # è·å–ä¸šåŠ¡è¯­ä¹‰ä¿¡æ¯
            business_context = self._extract_business_context(sheet_name, file_understanding_result)
            
            # 1. æè¿°æ€§ç»Ÿè®¡ -> æŸ±çŠ¶å›¾/ç®±çº¿å›¾
            if "descriptive_statistics" in statistics_indicators:
                query = f"""åŸºäºæè¿°æ€§ç»Ÿè®¡æŒ‡æ ‡ç”Ÿæˆå›¾è¡¨ï¼Œå±•ç¤ºå„åˆ—çš„ç»Ÿè®¡ç‰¹å¾ã€‚
ä¸šåŠ¡èƒŒæ™¯ï¼š{business_context}
ç»Ÿè®¡æŒ‡æ ‡å·²æä¾›ï¼Œè¯·æ ¹æ®å‡å€¼ã€ä¸­ä½æ•°ã€æ ‡å‡†å·®ç­‰æŒ‡æ ‡ç”Ÿæˆåˆé€‚çš„æŸ±çŠ¶å›¾æˆ–ç®±çº¿å›¾ã€‚"""
                
                try:
                    # ğŸ¯ é€šè¿‡ echarts_run.py è°ƒç”¨ echarts æ™ºèƒ½ä½“
                    echarts_result = query_echarts(simplified_indicators, query)
                    if echarts_result and echarts_result.get("echarts_config"):
                        echarts_structures.append({
                            "type": "descriptive_statistics",
                            "chart_type": "bar",
                            "title": f"{sheet_name} - æè¿°æ€§ç»Ÿè®¡",
                            "echarts_config": echarts_result["echarts_config"]
                        })
                except Exception as e:
                    logger.warning(f"âš ï¸ ç”Ÿæˆæè¿°æ€§ç»Ÿè®¡å›¾è¡¨å¤±è´¥: {e}")
            
            # 2. ç›¸å…³æ€§åˆ†æ -> çƒ­åŠ›å›¾/æ•£ç‚¹å›¾
            if "correlation_analysis" in statistics_indicators:
                query = f"""åŸºäºç›¸å…³æ€§åˆ†ææŒ‡æ ‡ç”Ÿæˆå›¾è¡¨ï¼Œå±•ç¤ºå˜é‡é—´çš„ç›¸å…³å…³ç³»ã€‚
ä¸šåŠ¡èƒŒæ™¯ï¼š{business_context}
ç»Ÿè®¡æŒ‡æ ‡å·²æä¾›ï¼Œè¯·æ ¹æ®ç›¸å…³æ€§çŸ©é˜µç”Ÿæˆçƒ­åŠ›å›¾æˆ–æ•£ç‚¹å›¾ã€‚"""
                
                try:
                    # ğŸ¯ é€šè¿‡ echarts_run.py è°ƒç”¨ echarts æ™ºèƒ½ä½“
                    echarts_result = query_echarts(simplified_indicators, query)
                    if echarts_result and echarts_result.get("echarts_config"):
                        echarts_structures.append({
                            "type": "correlation_analysis",
                            "chart_type": "heatmap",
                            "title": f"{sheet_name} - ç›¸å…³æ€§åˆ†æ",
                            "echarts_config": echarts_result["echarts_config"]
                        })
                except Exception as e:
                    logger.warning(f"âš ï¸ ç”Ÿæˆç›¸å…³æ€§åˆ†æå›¾è¡¨å¤±è´¥: {e}")
            
            # 3. é¢‘ç‡åˆ†æ -> æŸ±çŠ¶å›¾/é¥¼å›¾
            if "frequency_analysis" in statistics_indicators:
                query = f"""åŸºäºé¢‘ç‡åˆ†ææŒ‡æ ‡ç”Ÿæˆå›¾è¡¨ï¼Œå±•ç¤ºå„ç±»åˆ«çš„é¢‘ç‡åˆ†å¸ƒã€‚
ä¸šåŠ¡èƒŒæ™¯ï¼š{business_context}
ç»Ÿè®¡æŒ‡æ ‡å·²æä¾›ï¼Œè¯·æ ¹æ®é¢‘ç‡åˆ†å¸ƒæ•°æ®ç”ŸæˆæŸ±çŠ¶å›¾æˆ–é¥¼å›¾ã€‚"""
                
                try:
                    # ğŸ¯ é€šè¿‡ echarts_run.py è°ƒç”¨ echarts æ™ºèƒ½ä½“
                    echarts_result = query_echarts(simplified_indicators, query)
                    if echarts_result and echarts_result.get("echarts_config"):
                        echarts_structures.append({
                            "type": "frequency_analysis",
                            "chart_type": "bar",
                            "title": f"{sheet_name} - é¢‘ç‡åˆ†å¸ƒ",
                            "echarts_config": echarts_result["echarts_config"]
                        })
                except Exception as e:
                    logger.warning(f"âš ï¸ ç”Ÿæˆé¢‘ç‡åˆ†æå›¾è¡¨å¤±è´¥: {e}")
            
            logger.info(f"âœ… ä¸ºå·¥ä½œè¡¨ {sheet_name} ç”Ÿæˆäº† {len(echarts_structures)} ä¸ª ECharts ç»“æ„")
            return echarts_structures
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆ ECharts ç»“æ„å¤±è´¥: {e}")
            return []
    
    def _simplify_indicators(self, indicators: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç²¾ç®€ç»Ÿè®¡æŒ‡æ ‡ï¼Œåªä¿ç•™å…³é”®ä¿¡æ¯
        ä¸åŒ…å«å®Œæ•´çš„ç›¸å…³æ€§çŸ©é˜µã€å®Œæ•´é¢‘ç‡åˆ†å¸ƒç­‰å¤§æ•°æ®
        """
        simplified = {}
        
        # ä¿ç•™æè¿°æ€§ç»Ÿè®¡çš„å…³é”®æŒ‡æ ‡
        if "descriptive_statistics" in indicators:
            desc_stats = indicators["descriptive_statistics"]
            simplified["descriptive_statistics"] = {}
            for col, stats in list(desc_stats.items())[:20]:  # åªä¿ç•™å‰20åˆ—
                if isinstance(stats, dict):
                    simplified["descriptive_statistics"][col] = {
                        k: v for k, v in stats.items() 
                        if k in ["mean", "median", "std", "min", "max", "count", "q25", "q50", "q75"]
                    }
        
        # ä¿ç•™ç›¸å…³æ€§åˆ†æçš„å…³é”®ä¿¡æ¯ - âš ï¸ ä¸åŒ…å« correlation_matrixï¼ˆå¯èƒ½éå¸¸å¤§ï¼‰
        if "correlation_analysis" in indicators:
            corr_analysis = indicators["correlation_analysis"]
            if isinstance(corr_analysis, dict):
                simplified["correlation_analysis"] = {
                    "strong_correlations": corr_analysis.get("strong_correlations", [])[:20]  # åªä¿ç•™å‰20ä¸ªå¼ºç›¸å…³
                    # ä¸åŒ…å« correlation_matrixï¼Œå› ä¸ºå®ƒå¯èƒ½éå¸¸å¤§ï¼ˆNxNçŸ©é˜µï¼‰
                }
        
        # ä¿ç•™é¢‘ç‡åˆ†æçš„å…³é”®ä¿¡æ¯ - âš ï¸ ä¸åŒ…å«å®Œæ•´çš„ frequency å­—å…¸
        if "frequency_analysis" in indicators:
            freq_analysis = indicators["frequency_analysis"]
            simplified["frequency_analysis"] = {}
            for col, freq in list(freq_analysis.items())[:10]:  # åªä¿ç•™å‰10åˆ—
                if isinstance(freq, dict):
                    simplified["frequency_analysis"][col] = {
                        "unique_count": freq.get("unique_count"),
                        "total_count": freq.get("total_count"),
                        "top_10": freq.get("top_10", {})  # åªä¿ç•™ top_10ï¼Œä¸ä¿ç•™å®Œæ•´çš„ frequency å­—å…¸
                    }
        
        # ä¿ç•™åˆ†å¸ƒåˆ†æçš„å…³é”®æŒ‡æ ‡
        if "distribution_analysis" in indicators:
            dist_analysis = indicators["distribution_analysis"]
            simplified["distribution_analysis"] = {}
            for col, dist in list(dist_analysis.items())[:10]:  # åªä¿ç•™å‰10åˆ—
                if isinstance(dist, dict):
                    simplified["distribution_analysis"][col] = {
                        k: v for k, v in dist.items() 
                        if k in ["skewness", "kurtosis", "distribution_type"]
                    }
        
        return simplified
    
    def _extract_business_context(self, sheet_name: str, file_understanding_result: Dict[str, Any]) -> str:
        """æå–ä¸šåŠ¡è¯­ä¹‰ä¸Šä¸‹æ–‡"""
        if not file_understanding_result:
            return f"å·¥ä½œè¡¨ {sheet_name} çš„æ•°æ®åˆ†æ"
        
        key_columns = file_understanding_result.get("key_columns", [])
        user_intent = file_understanding_result.get("user_intent", "")
        
        context_parts = []
        if user_intent:
            context_parts.append(f"ç”¨æˆ·æ„å›¾ï¼š{user_intent}")
        if key_columns:
            context_parts.append(f"å…³é”®åˆ—ï¼š{', '.join(key_columns[:5])}")
        
        return "ï¼›".join(context_parts) if context_parts else f"å·¥ä½œè¡¨ {sheet_name} çš„æ•°æ®åˆ†æ"


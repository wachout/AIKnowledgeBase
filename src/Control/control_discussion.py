# -*- coding:utf-8 -*-
"""
åœ†æ¡Œè®¨è®ºç³»ç»Ÿæ§åˆ¶æ¨¡å—
- ç¬¬ä¸€å±‚è®¨è®ºå±‚ï¼šæ¯ä¸ªæ™ºèƒ½ä½“å‘è¨€ä¿å­˜åˆ° discussion/discussion_id/discuss
- ç¬¬äºŒå±‚å®æ–½æ­¥éª¤å±‚ï¼šæ¯ä¸ªå®æ–½æ–¹æ¡ˆä¿å­˜åˆ° discussion/discussion_id/implement
- ç¬¬ä¸‰å±‚å…·åƒåŒ–å±‚ï¼šé˜…è¯»å®æ–½æ­¥éª¤ï¼ŒæŒ‰é¢†åŸŸå…·åƒåŒ–ï¼ˆæ•°å­—åŒ–+å…·åƒåŒ–ï¼‰ï¼Œç»“æœä¿å­˜åˆ° discussion/discussion_id/concretization
"""

import os
import re
import json
import time
import logging
import uuid
import asyncio
import traceback
from typing import Dict, Any, List, Optional
from datetime import datetime

from Db.sqlite_db import cSingleSqlite
from Config.llm_config import get_chat_tongyi
from Roles import RoundtableDiscussion

# å¯¼å…¥ä¸‰å±‚ç³»ç»Ÿç»„ä»¶
from Roles.hierarchy import (
    # ç±»å‹å®šä¹‰
    Task, Objective, Constraint, DecisionOutput, ImplementationOutput,
    ExecutionStatus, ImplementationRole,
    # å®æ–½å±‚
    ImplementationLayer,
    # æ£€éªŒå±‚  
    ValidationLayer
)
from Roles.hierarchy.layers.implementation_layer import ImplementGroupScheduler, ImplementationGroup
from Roles.hierarchy.layers.implementation_roundtable import ImplementationDiscussion
from Roles.hierarchy.layers.concretization_roundtable import ConcretizationDiscussion

logger = logging.getLogger(__name__)


class DiscussionControl:
    """åœ†æ¡Œè®¨è®ºç³»ç»Ÿæ§åˆ¶ç±»
    æ”¯æŒä¸‰å±‚ç³»ç»Ÿï¼š
    1. ç¬¬ä¸€å±‚è®¨è®ºå±‚ï¼šå‘è¨€ä¿å­˜åˆ° discuss/
    2. ç¬¬äºŒå±‚å®æ–½æ­¥éª¤å±‚ï¼šå®æ–½æ–¹æ¡ˆä¿å­˜åˆ° implement/
    3. ç¬¬ä¸‰å±‚å…·åƒåŒ–å±‚ï¼šæ•°å­—/å…·åƒåŒ–/æŠ½è±¡åŒ–å·¥ç¨‹å¸ˆ + æŒ‰é¢†åŸŸå…·åƒåŒ–æ™ºèƒ½ä½“ï¼Œç»“æœä¿å­˜åˆ° concretization/
    """
    
    def __init__(self):
        # å®æ–½ç»„è°ƒåº¦å™¨
        self.impl_scheduler = ImplementGroupScheduler()
        # LLMå®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._llm_instance = None
    
    def _get_llm_instance(self):
        """è·å–LLMå®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        if self._llm_instance is None:
            self._llm_instance = get_chat_tongyi()
        return self._llm_instance
    
    def _convert_to_decision_output(self, discussion_state: dict, final_report: dict, query: str) -> DecisionOutput:
        """
        å°†åœ†æ¡Œè®¨è®ºç»“æœè½¬æ¢ä¸º DecisionOutput
        
        Args:
            discussion_state: è®¨è®ºçŠ¶æ€
            final_report: æœ€ç»ˆæŠ¥å‘Š
            query: åŸå§‹æŸ¥è¯¢
        
        Returns:
            DecisionOutput
        """
        # æå–å…±è¯†ç‚¹ä½œä¸ºç›®æ ‡
        consensus_data = discussion_state.get('consensus_data', {})
        key_points = consensus_data.get('key_points', [])
        
        objectives = []
        for i, point in enumerate(key_points[:5]):  # æœ€å¤š5ä¸ªç›®æ ‡
            obj = Objective(
                name=f"å…±è¯†ç›®æ ‡_{i+1}",
                description=point if isinstance(point, str) else str(point),
                priority=5 - i
            )
            objectives.append(obj)
        
        # æå–è¡ŒåŠ¨å»ºè®®ä½œä¸ºä»»åŠ¡
        final_report_data = discussion_state.get('final_report', {}) if not final_report else final_report
        action_recommendations = final_report_data.get('action_recommendations', [])
        key_insights = final_report_data.get('key_insights', [])
        
        tasks = []
        for i, action in enumerate(action_recommendations[:5]):  # æœ€å¤š5ä¸ªä»»åŠ¡
            task = Task(
                name=f"å®æ–½ä»»åŠ¡_{i+1}",
                description=action if isinstance(action, str) else str(action),
                priority=5 - i,
                status=ExecutionStatus.PENDING
            )
            tasks.append(task)
        
        # å¦‚æœæ²¡æœ‰ä»»åŠ¡ï¼Œä»å…³é”®æ´å¯Ÿåˆ›å»º
        if not tasks and key_insights:
            for i, insight in enumerate(key_insights[:3]):
                task = Task(
                    name=f"æ´å¯Ÿå®æ–½_{i+1}",
                    description=insight if isinstance(insight, str) else str(insight),
                    priority=3 - i,
                    status=ExecutionStatus.PENDING
                )
                tasks.append(task)
        
        # æå–åˆ†æ­§ç‚¹ä½œä¸ºçº¦æŸ
        divergences = consensus_data.get('divergences', [])
        constraints = []
        for i, div in enumerate(divergences[:3]):
            constraint = Constraint(
                name=f"åˆ†æ­§çº¦æŸ_{i+1}",
                description=div if isinstance(div, str) else str(div),
                constraint_type="soft"
            )
            constraints.append(constraint)
        
        # æ„å»ºè®¨è®ºæ‘˜è¦
        total_rounds = discussion_state.get('current_round', 0)
        consensus_level = consensus_data.get('overall_level', 0.0)
        discussion_summary = f"""
åœ†æ¡Œè®¨è®ºå®Œæˆï¼Œå…±è¿›è¡Œ {total_rounds} è½®è®¨è®ºã€‚
æœ€ç»ˆå…±è¯†æ°´å¹³: {consensus_level:.2f}
å…±è¯†ç‚¹: {len(key_points)} ä¸ª
åˆ†æ­§ç‚¹: {len(divergences)} ä¸ª
è¡ŒåŠ¨å»ºè®®: {len(action_recommendations)} æ¡
        """.strip()
        
        return DecisionOutput(
            query=query,
            objectives=objectives,
            tasks=tasks,
            constraints=constraints,
            success_criteria=[f"å®Œæˆå…±è¯†æ°´å¹³: {consensus_level:.2f}"],
            discussion_summary=discussion_summary
        )
    
    def _run_implementation_layer(
        self,
        decision_output: DecisionOutput,
        discussion_state: dict,
        discussion_base_path: str
    ):
        """
        è¿è¡Œç¬¬äºŒå±‚ï¼šå®æ–½è®¨è®ºç»„
        
        Args:
            decision_output: ç¬¬ä¸€å±‚å†³ç­–è¾“å‡º
            discussion_state: è®¨è®ºçŠ¶æ€
            discussion_base_path: è®¨è®ºæ–‡ä»¶å¤¹è·¯å¾„
        
        Returns:
            (impl_outputs: List[ImplementationOutput], impl_result: ç¬¬äºŒå±‚è®¨è®ºç»“æœï¼Œä¾›ç¬¬ä¸‰å±‚ä½¿ç”¨)
        """
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ› ï¸ ã€ç¬¬äºŒå±‚ã€‘å¯åŠ¨å®æ–½è®¨è®ºç»„...")
        logger.info("=" * 60)
        
        impl_outputs = []
        impl_result = None
        llm_instance = self._get_llm_instance()
        
        # åˆ›å»ºå®æ–½è®¨è®ºç³»ç»Ÿ
        impl_discussion = ImplementationDiscussion(llm_adapter=llm_instance)
        
        # æ„å»ºç¬¬ä¸€å±‚å®Œæ•´è¾“å‡ºï¼ˆä¾›ç¬¬äºŒå±‚ä½¿ç”¨ï¼›ç¬¬äºŒå±‚å°†æŒ‰ç¬¬ä¸€å±‚é¢†åŸŸä¸“å®¶ä¸€ä¸€å¯¹åº”åˆ›å»ºå®æ–½æ­¥éª¤æ™ºèƒ½ä½“ï¼‰
        first_layer_output = {
            'discussion_id': discussion_state.get('discussion_id', ''),
            'discussion_summary': discussion_state.get('final_report', {}).get('discussion_summary', ''),
            'consensus_data': discussion_state.get('consensus_data', {}),
            'key_insights': discussion_state.get('final_report', {}).get('key_insights', []),
            'action_recommendations': discussion_state.get('final_report', {}).get('action_recommendations', []),
            'participants': discussion_state.get('participants', []),
            'total_rounds': discussion_state.get('current_round', 0),
            'rounds': discussion_state.get('rounds', []),  # å„è½®å‘è¨€ï¼Œä¾›ç¬¬äºŒå±‚æŒ‰é¢†åŸŸæå–ä¸“å®¶å‘è¨€ä¸è´¨ç–‘è€…æ„è§
            'user_goal': discussion_state.get('topic', ''),  # ç”¨æˆ·ç›®æ ‡ï¼Œç¬¬äºŒå±‚é¡»ç´§æ‰£æ­¤ç›®æ ‡ç»™å‡ºå¯å®æ–½æªæ–½
            'discuss_dir': os.path.abspath(os.path.join(discussion_base_path, "discuss")),  # ç¬¬ä¸€å±‚ discuss ç›®å½•ï¼Œä¾› JSON è§£æå¤±è´¥æ—¶å›é€€è¯»å–
        }
        
        # å¦‚æœæœ‰ç¬¬ä¸€å±‚æ±‡æ€»æ–‡æ¡£ç´¢å¼•ï¼Œä¼ å…¥
        if 'layer1_summary' in discussion_state:
            first_layer_output['layer1_summary'] = discussion_state['layer1_summary']
        
        # æ„å»ºä»»åŠ¡åˆ—è¡¨
        task_list = []
        for task in decision_output.tasks:
            task_list.append({
                'name': task.name,
                'description': task.description,
                'task_id': task.task_id,
                'priority': task.priority if hasattr(task, 'priority') else 3
            })
        
        logger.info(f"ç¬¬äºŒå±‚æ¥æ”¶ {len(task_list)} ä¸ªä»»åŠ¡")
        if first_layer_output.get('layer1_summary'):
            logger.info("å·²åŠ è½½ç¬¬ä¸€å±‚æ±‡æ€»æ–‡æ¡£ç´¢å¼•")
        
        try:
            # è¿è¡Œå¼‚æ­¥è®¨è®º
            async def run_discussion():
                outputs = []
                async for chunk in impl_discussion.run_implementation_discussion(
                    task_list=task_list,
                    first_layer_output=first_layer_output
                ):
                    # logger.info(chunk.strip())
                    outputs.append(chunk)
                return outputs
            
            # åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡Œå¼‚æ­¥ä»£ç 
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    import concurrent.futures
                    future = asyncio.run_coroutine_threadsafe(run_discussion(), loop)
                    future.result(timeout=600)
                else:
                    asyncio.run(run_discussion())
            except RuntimeError:
                asyncio.run(run_discussion())
            
            # æ”¶é›†è®¨è®ºç»“æœ
            result = impl_discussion._current_result
            impl_result = result
            if result:
                impl_output = ImplementationOutput(
                    task_id=result.task_id,
                    status=ExecutionStatus.COMPLETED if result.success else ExecutionStatus.FAILED,
                    started_at=result.started_at,
                    completed_at=result.completed_at
                )
                impl_output.metrics['consensus_level'] = result.final_consensus_level
                impl_outputs.append(impl_output)
                
                logger.info(f"âœ… å®æ–½è®¨è®ºå®Œæˆï¼Œå…±è¯†åº¦: {result.final_consensus_level:.2f}")
                
                # ç¬¬äºŒå±‚å®æ–½æ–¹æ¡ˆå·²ä¿å­˜åˆ° discussion/discussion_id/implement
                self._save_implementation_result(
                    discussion_base_path,
                    decision_output.tasks[0] if decision_output.tasks else None,
                    result
                )
                # ç§‘å­¦å®¶åˆ†æç»“æœ -> implement/
                if result.scholar_analysis:
                    self._save_layer2_scholar_result(discussion_base_path, result)
                # ç»¼åˆè€…äº§å‡ºï¼ˆç»¼åˆæ–¹æ¡ˆï¼‰-> implement/
                if result.synthesized_plan:
                    self._save_layer2_synthesized_plan(discussion_base_path, result)
                # ç¬¬äºŒå±‚æ™ºèƒ½ä½“ä¿¡æ¯ä¿å­˜åˆ° roles/ï¼Œä»¥ layer_2_ å‰ç¼€åŒºåˆ†ç¬¬ä¸€å±‚
                layer2_participants = []
                layer2_agents = []
                for expert in (result.experts_created or []):
                    name = expert.get('name') or expert.get('role') or expert.get('domain') or 'expert'
                    self._save_agent_config(discussion_base_path, f"layer_2_{name}", expert)
                    layer2_participants.append(name)
                    layer2_agents.append({
                        "name": name,
                        "domain": expert.get("domain", ""),
                        "role": expert.get("role", ""),
                    })
                layer2_speeches = []
                # ç¬¬äºŒå±‚å®æ–½æ–¹æ¡ˆä¿å­˜åˆ° implement/
                impl_dir = os.path.join(discussion_base_path, "implement")
                os.makedirs(impl_dir, exist_ok=True)
                for i, prop in enumerate(result.expert_proposals or []):
                    safe = re.sub(r'[^\w\u4e00-\u9fa5]', '_', (prop.get('expert_name') or f'proposal_{i}')[:50])
                    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                    rel_md = f"implement/impl_expert_{safe}_proposal_{ts}.md"
                    try:
                        with open(os.path.join(impl_dir, f"impl_expert_{safe}_proposal_{ts}.md"), 'w', encoding='utf-8') as f:
                            f.write(prop.get('content', ''))
                        with open(os.path.join(impl_dir, f"impl_expert_{safe}_proposal_{ts}.json"), 'w', encoding='utf-8') as f:
                            json.dump({"expert_name": prop.get("expert_name"), "domain": prop.get("domain"), "structured": prop.get("structured")}, f, ensure_ascii=False, indent=2)
                        layer2_speeches.append({
                            "speaker": prop.get("expert_name") or f"ä¸“å®¶_{i}",
                            "relative_file_path": rel_md,
                            "timestamp": ts,
                        })
                    except Exception as ex:
                        logger.warning(f"ä¿å­˜ç¬¬äºŒå±‚ä¸“å®¶å‘è¨€å¤±è´¥: {ex}")
                discussion_state['layer2'] = {
                    'participants': layer2_participants,
                    'agents': layer2_agents,
                    'speeches': layer2_speeches,
                    'completed_at': datetime.now().isoformat(),
                }
                    
        except Exception as e:
            logger.error(f"âŒ å®æ–½è®¨è®ºå¤±è´¥: {e}", exc_info=True)
            impl_output = ImplementationOutput(
                task_id=task_list[0].get('task_id', '') if task_list else '',
                status=ExecutionStatus.FAILED
            )
            impl_outputs.append(impl_output)
        
        # æ›´æ–°è®¨è®ºçŠ¶æ€
        discussion_state['implementation_layer'] = {
            'status': 'completed',
            'task_count': len(decision_output.tasks),
            'completed_count': sum(1 for o in impl_outputs if o.status == ExecutionStatus.COMPLETED),
            'timestamp': datetime.now().isoformat()
        }
        self._save_discussion_state(discussion_base_path, discussion_state)
        
        logger.info(f"\nğŸ› ï¸ å®æ–½è®¨è®ºç»„å®Œæˆï¼Œå…±å¤„ç† {len(impl_outputs)} ä¸ªä»»åŠ¡")
        return impl_outputs, impl_result

    def _run_concretization_layer(
        self,
        discussion_base_path: str,
        discussion_id: str,
    ):
        """
        è¿è¡Œç¬¬ä¸‰å±‚å…·åƒåŒ–å±‚ï¼šé˜…è¯» implement/ ä¸­çš„å®æ–½æ­¥éª¤ï¼ŒæŒ‰é¢†åŸŸåˆ›å»ºå…·åƒåŒ–æ™ºèƒ½ä½“ï¼Œ
        æ‰§è¡Œæ•°å­—åŒ–+å…·åƒåŒ–ï¼ˆç¬¦åˆç¬¬ä¸€æ€§åŸç†ã€ç‰©ç†å®ˆæ’ã€ææ–™çº¦æŸç­‰ï¼‰ï¼Œç»“æœä¿å­˜åˆ° concretization/ã€‚
        """
        try:
            llm_instance = self._get_llm_instance()
            conc_discussion = ConcretizationDiscussion(llm_adapter=llm_instance)

            async def run_conc():
                outputs = []
                async for chunk in conc_discussion.run_concretization(
                    discussion_base_path=discussion_base_path,
                    discussion_id=discussion_id,
                ):
                    # logger.info(chunk.strip())
                    outputs.append(chunk)
                return outputs

            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    import concurrent.futures
                    future = asyncio.run_coroutine_threadsafe(run_conc(), loop)
                    future.result(timeout=600)
                else:
                    asyncio.run(run_conc())
            except RuntimeError:
                asyncio.run(run_conc())
            logger.info("âœ… ç¬¬ä¸‰å±‚å…·åƒåŒ–å±‚å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ ç¬¬ä¸‰å±‚å…·åƒåŒ–å±‚æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)

    def _save_implementation_result(self, discussion_base_path: str, task, result):
        """ä¿å­˜å®æ–½è®¨è®ºç»“æœåˆ° discussion/discussion_id/implement/"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            task_name = task.name if task and hasattr(task, 'name') else result.task_name
            safe_task_name = re.sub(r'[^\w\u4e00-\u9fa5]', '_', task_name)
            
            impl_dir = os.path.join(discussion_base_path, "implement")
            os.makedirs(impl_dir, exist_ok=True)
            
            json_filename = f"impl_discussion_{safe_task_name}_{timestamp}.json"
            json_filepath = os.path.join(impl_dir, json_filename)
            
            impl_data = {
                "task_name": task_name,
                "task_id": task.task_id if task and hasattr(task, 'task_id') else result.task_id,
                "discussion_id": result.discussion_id,
                "started_at": result.started_at.isoformat() if result.started_at else None,
                "completed_at": result.completed_at.isoformat() if result.completed_at else None,
                "total_rounds": result.total_rounds,
                "final_consensus_level": result.final_consensus_level,
                "key_decisions": result.key_decisions,
                "implementation_plan": result.implementation_plan,
                "success": result.success,
                # ç»“æ„åŒ–æ•°æ®
                "scholar_analysis": result.scholar_analysis,
                "experts_created": result.experts_created,
                "expert_proposals_count": len(result.expert_proposals),
                "cross_reviews_count": len(result.cross_reviews) if hasattr(result, 'cross_reviews') else 0,
                "synthesized_plan": result.synthesized_plan,
                "challenges": result.challenges
            }
            
            with open(json_filepath, 'w', encoding='utf-8') as f:
                json.dump(impl_data, f, ensure_ascii=False, indent=2)
            logger.info(f"ä¿å­˜å®æ–½è®¨è®ºç»“æœ: {json_filepath}")
            
            md_filename = f"impl_report_{safe_task_name}_{timestamp}.md"
            md_filepath = os.path.join(impl_dir, md_filename)
            
            md_content = self._generate_implementation_report_md(task, result)
            
            with open(md_filepath, 'w', encoding='utf-8') as f:
                f.write(md_content)
            logger.info(f"ä¿å­˜å®æ–½è®¨è®ºæŠ¥å‘Š: {md_filepath}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å®æ–½è®¨è®ºç»“æœå¤±è´¥: {e}")
    
    def _save_layer2_scholar_result(self, discussion_base_path: str, result):
        """å®æ–½å±‚ï¼šç§‘å­¦å®¶æ™ºèƒ½ä½“ç»“æœä¿å­˜åˆ° discussion/discussion_id/implement"""
        try:
            impl_dir = os.path.join(discussion_base_path, "implement")
            os.makedirs(impl_dir, exist_ok=True)
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            json_path = os.path.join(impl_dir, f"impl_scholar_analysis_{ts}.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(result.scholar_analysis, f, ensure_ascii=False, indent=2)
            logger.info(f"ä¿å­˜å®æ–½å±‚ç§‘å­¦å®¶åˆ†æåˆ° implement: {json_path}")
        except Exception as e:
            logger.warning(f"ä¿å­˜å®æ–½å±‚ç§‘å­¦å®¶ç»“æœå¤±è´¥: {e}")
    
    def _save_layer2_synthesized_plan(self, discussion_base_path: str, result):
        """å®æ–½å±‚ï¼šç»¼åˆè€…æ™ºèƒ½ä½“ç»“æœï¼ˆç»¼åˆæ–¹æ¡ˆï¼‰ä¿å­˜åˆ° discussion/discussion_id/implement"""
        try:
            impl_dir = os.path.join(discussion_base_path, "implement")
            os.makedirs(impl_dir, exist_ok=True)
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            json_path = os.path.join(impl_dir, f"impl_synthesized_plan_{ts}.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(result.synthesized_plan, f, ensure_ascii=False, indent=2)
            md_path = os.path.join(impl_dir, f"impl_synthesized_plan_{ts}.md")
            plan = result.synthesized_plan or {}
            summary = plan.get("summary", "")
            phases = plan.get("implementation_phases", [])
            md_lines = ["# å®æ–½ç»¼åˆæ–¹æ¡ˆ\n\n", f"**æ‘˜è¦**: {summary}\n\n", "## å®æ–½é˜¶æ®µ\n\n"]
            for i, ph in enumerate(phases, 1):
                if isinstance(ph, dict):
                    md_lines.append(f"### {i}. {ph.get('name', f'é˜¶æ®µ{i}')}\n\n")
                    for j, step in enumerate(ph.get("steps", []), 1):
                        s = step if isinstance(step, dict) else {"name": str(step)}
                        md_lines.append(f"- {s.get('name', str(step))}\n")
                    md_lines.append("\n")
            with open(md_path, 'w', encoding='utf-8') as f:
                f.write("".join(md_lines))
            logger.info(f"ä¿å­˜å®æ–½å±‚ç»¼åˆæ–¹æ¡ˆåˆ° implement: {json_path}, {md_path}")
        except Exception as e:
            logger.warning(f"ä¿å­˜å®æ–½å±‚ç»¼åˆæ–¹æ¡ˆå¤±è´¥: {e}")
    
    def _generate_implementation_report_md(self, task, result) -> str:
        """ç”Ÿæˆå®æ–½è®¨è®ºçš„ Markdown æŠ¥å‘Š"""
        task_name = task.name if task and hasattr(task, 'name') else result.task_name
        parts = []
        parts.append(f"""# å®æ–½è®¨è®ºæŠ¥å‘Š

**ä»»åŠ¡**: {task_name}
**è®¨è®º ID**: {result.discussion_id}
**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**çŠ¶æ€**: {'æˆåŠŸ' if result.success else 'æœªå®Œæˆ'}
**å…±è¯†åº¦**: {result.final_consensus_level:.2f}

---
""")
        
        # ç§‘å­¦å®¶åˆ†ææ‘˜è¦
        scholar = result.scholar_analysis
        if scholar:
            parts.append(f"""## ç§‘å­¦å®¶åˆ†æ

- **é¡¹ç›®ç±»å‹**: {scholar.get('project_type', 'æœªåˆ†æ')}
- **ä»»åŠ¡åˆ†æ**: {scholar.get('task_analysis', 'æ— ')[:200]}
- **æ‰€éœ€ä¸“å®¶**: {len(scholar.get('required_experts', []))} ä½

""")
        
        # ä¸“å®¶å›¢é˜Ÿ
        experts = result.experts_created
        if experts:
            parts.append(f"## ä¸“å®¶å›¢é˜Ÿ ({len(experts)} ä½)\n\n")
            parts.append("| åºå· | ä¸“å®¶ | é¢†åŸŸ | è§’è‰² |\n")
            parts.append("|------|------|------|------|\n")
            for i, expert in enumerate(experts, 1):
                name = expert.get('name', 'æœªçŸ¥')
                domain = expert.get('domain', 'æœªçŸ¥')
                role = expert.get('role', 'æœªçŸ¥')
                parts.append(f"| {i} | {name} | {domain} | {role} |\n")
            parts.append("\n")
        
        # å„ä¸“å®¶æ–¹æ¡ˆæ‘˜è¦
        proposals = result.expert_proposals
        if proposals:
            parts.append(f"## ä¸“å®¶æ–¹æ¡ˆæ‘˜è¦ ({len(proposals)} ä¸ª)\n\n")
            for i, prop in enumerate(proposals, 1):
                expert_name = prop.get('expert_name', f'ä¸“å®¶{i}')
                domain = prop.get('domain', 'æœªçŸ¥é¢†åŸŸ')
                content = prop.get('content', '')[:500]
                parts.append(f"### {i}. {expert_name} ({domain})\n\n{content}\n\n")
        
        # äº¤å‰å®¡é˜…ç»“æœ
        cross_reviews = result.cross_reviews if hasattr(result, 'cross_reviews') else []
        if cross_reviews:
            parts.append(f"## äº¤å‰å®¡é˜…ç»“æœ ({len(cross_reviews)} æ¡)\n\n")
            parts.append("| å®¡é˜…è€… | å®¡é˜…å¯¹è±¡ | ç«‹åœº | ä¼˜ç‚¹ | æ‹…å¿§ |\n")
            parts.append("|--------|----------|------|------|------|\n")
            for review in cross_reviews:
                reviewer = review.get('reviewer', 'æœªçŸ¥')
                target = review.get('target_expert', 'æœªçŸ¥')
                stance = review.get('stance', 'neutral')
                strengths = ', '.join(review.get('strengths', [])[:2])
                concerns = ', '.join(review.get('concerns', [])[:2])
                parts.append(f"| {reviewer} | {target} | {stance} | {strengths[:50]} | {concerns[:50]} |\n")
            parts.append("\n")
        
        # ç»¼åˆå®æ–½è®¡åˆ’
        if result.implementation_plan:
            parts.append(f"## ç»¼åˆå®æ–½è®¡åˆ’\n\n{result.implementation_plan}\n\n")
        
        # å…³é”®å†³ç­–
        if result.key_decisions:
            parts.append(f"## å…³é”®å†³ç­– ({len(result.key_decisions)} é¡¹)\n\n")
            for i, decision in enumerate(result.key_decisions, 1):
                parts.append(f"{i}. {decision}\n")
            parts.append("\n")
        
        # è´¨ç–‘ç‚¹
        challenges = result.challenges
        if challenges:
            parts.append(f"## è´¨ç–‘ç‚¹ ({len(challenges)} ä¸ª)\n\n")
            for i, ch in enumerate(challenges, 1):
                if isinstance(ch, dict):
                    point = ch.get('point', '')
                    severity = ch.get('severity', 'medium')
                    suggestion = ch.get('suggestion', '')
                    parts.append(f"{i}. **[{severity.upper()}]** {point}\n")
                    if suggestion:
                        parts.append(f"   - å»ºè®®: {suggestion}\n")
                else:
                    parts.append(f"{i}. {ch}\n")
            parts.append("\n")
        
        return "".join(parts)
    
    def _generate_layer1_summary_document(
        self,
        discussion_base_path: str,
        discussion_state: dict,
        final_report: dict,
        query: str
    ) -> Optional[str]:
        """
        ç”Ÿæˆç¬¬ä¸€å±‚åœ†æ¡Œè®¨è®ºçš„æ±‡æ€»æ–‡æ¡£ï¼ˆå¸¦ç›®å½•ç´¢å¼•ï¼‰
        
        å°†æ‰€æœ‰æ™ºèƒ½ä½“çš„å‘è¨€ã€è´¨ç–‘è€…å‘è¨€ã€å…±è¯†æ•°æ®ç­‰æ±‡æ€»ä¸ºå¸¦ç›®å½•çš„æ–‡æ¡£ï¼Œ
        ä¾›ç¬¬äºŒå±‚å®æ–½å±‚ä¸“å®¶æŒ‰é¢†åŸŸå¿«é€ŸæŸ¥é˜…ï¼ŒèŠ‚çœ tokenã€‚
        
        ç”Ÿæˆä¸¤ä¸ªæ–‡ä»¶:
        1. Markdown å¯è¯»æ–‡æ¡£ï¼ˆå¸¦ç›®å½•ï¼‰
        2. JSON ç»“æ„åŒ–ç´¢å¼•ï¼ˆä¾›ç¨‹åºåŒ–æŸ¥è¯¢ï¼‰
        
        Args:
            discussion_base_path: è®¨è®ºæ–‡ä»¶å¤¹è·¯å¾„
            discussion_state: å®Œæ•´è®¨è®ºçŠ¶æ€
            final_report: æœ€ç»ˆæŠ¥å‘Š
            query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            
        Returns:
            æ±‡æ€»æ–‡æ¡£è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            discuss_dir = os.path.join(discussion_base_path, "discuss")
            os.makedirs(discuss_dir, exist_ok=True)
            
            # ---- æ”¶é›†æ‰€æœ‰å‘è¨€æ•°æ® ----
            rounds_data = discussion_state.get('rounds', [])
            all_speeches_by_speaker = {}  # {speaker: [speech, ...]}
            all_speeches_by_round = {}    # {round_num: [speech, ...]}
            skeptic_speeches = []
            
            for round_data in rounds_data:
                round_num = round_data.get('round_number', 0)
                speeches = round_data.get('speeches', [])
                all_speeches_by_round[round_num] = []
                
                for speech_data in speeches:
                    speaker = speech_data.get('speaker', 'æœªçŸ¥')
                    is_skeptic = speech_data.get('is_skeptic', False)
                    speech_entry = {
                        'round': round_num,
                        'thinking': speech_data.get('thinking', ''),
                        'speech': speech_data.get('speech', ''),
                        'is_skeptic': is_skeptic,
                        'target_expert': speech_data.get('target_expert', ''),
                    }
                    
                    if speaker not in all_speeches_by_speaker:
                        all_speeches_by_speaker[speaker] = []
                    all_speeches_by_speaker[speaker].append(speech_entry)
                    all_speeches_by_round[round_num].append({**speech_entry, 'speaker': speaker})
                    
                    if is_skeptic:
                        skeptic_speeches.append({**speech_entry, 'speaker': speaker})
            
            # ---- Markdown æ±‡æ€»æ–‡æ¡£ ----
            md = []
            total_rounds = len(rounds_data)
            total_speeches = sum(len(r.get('speeches', [])) for r in rounds_data)
            participants = discussion_state.get('participants', [])
            consensus_level = discussion_state.get('consensus_data', {}).get('overall_level', 0.0)
            
            md.append(f"""# åœ†æ¡Œè®¨è®ºæ±‡æ€»æ–‡æ¡£

**è®¨è®ºä¸»é¢˜**: {query}
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ€»è½®æ¬¡**: {total_rounds} | **æ€»å‘è¨€**: {total_speeches} | **å‚ä¸è€…**: {len(participants)} | **å…±è¯†**: {consensus_level:.2f}

---

""")
            
            # ---- ç›®å½• (TOC) ----
            md.append("## ç›®å½•\n\n")
            toc_idx = 1
            
            md.append(f"{toc_idx}. [ä¸“å®¶å‘è¨€ç´¢å¼•ï¼ˆæŒ‰è§’è‰²ï¼‰](#ä¸“å®¶å‘è¨€ç´¢å¼•æŒ‰è§’è‰²)\n")
            toc_idx += 1
            for speaker_name in all_speeches_by_speaker:
                safe_anchor = re.sub(r'[^\w\u4e00-\u9fa5]', '', speaker_name)
                any_skeptic = any(s['is_skeptic'] for s in all_speeches_by_speaker[speaker_name])
                label = f"{speaker_name}ï¼ˆè´¨ç–‘è€…ï¼‰" if any_skeptic else speaker_name
                md.append(f"  - [{label}](#{safe_anchor})\n")
            
            if skeptic_speeches:
                md.append(f"{toc_idx}. [è´¨ç–‘è€…å‘è¨€æ±‡æ€»](#è´¨ç–‘è€…å‘è¨€æ±‡æ€»)\n")
                toc_idx += 1
            
            md.append(f"{toc_idx}. [å„è½®æ¬¡è®¨è®ºè®°å½•](#å„è½®æ¬¡è®¨è®ºè®°å½•)\n")
            toc_idx += 1
            for rn in sorted(all_speeches_by_round.keys()):
                md.append(f"  - [ç¬¬{rn}è½®](#ç¬¬{rn}è½®è®¨è®º)\n")
            
            md.append(f"{toc_idx}. [å…±è¯†ä¸åˆ†æ­§](#å…±è¯†ä¸åˆ†æ­§)\n")
            toc_idx += 1
            md.append(f"{toc_idx}. [æœ€ç»ˆæŠ¥å‘Šä¸è¡ŒåŠ¨å»ºè®®](#æœ€ç»ˆæŠ¥å‘Šä¸è¡ŒåŠ¨å»ºè®®)\n")
            md.append("\n---\n\n")
            
            # ---- ä¸“å®¶å‘è¨€ç´¢å¼• ----
            md.append("## ä¸“å®¶å‘è¨€ç´¢å¼•ï¼ˆæŒ‰è§’è‰²ï¼‰\n\n")
            md.append("> ç¬¬äºŒå±‚å®æ–½ä¸“å®¶å¯æ ¹æ®è§’è‰²åç§°å¿«é€Ÿå®šä½ç›¸å…³é¢†åŸŸçš„è®¨è®ºå†…å®¹ã€‚\n\n")
            
            for speaker_name, speeches in all_speeches_by_speaker.items():
                any_skeptic = any(s['is_skeptic'] for s in speeches)
                role_label = f"{speaker_name}ï¼ˆè´¨ç–‘è€…ï¼‰" if any_skeptic else speaker_name
                md.append(f"### {role_label}\n\n")
                md.append(f"**å‘è¨€æ¬¡æ•°**: {len(speeches)}\n\n")
                
                for idx, sp in enumerate(speeches, 1):
                    md.append(f"#### ç¬¬{sp['round']}è½® å‘è¨€#{idx}\n\n")
                    if sp['is_skeptic'] and sp.get('target_expert'):
                        md.append(f"**é’ˆå¯¹**: {sp['target_expert']}\n\n")
                    if sp.get('thinking'):
                        md.append(f"**æ€è€ƒ**: {sp['thinking'][:500]}\n\n")
                    md.append(f"**å†…å®¹**: {sp.get('speech', 'æ— ')}\n\n")
                md.append("---\n\n")
            
            # ---- è´¨ç–‘è€…å‘è¨€æ±‡æ€» ----
            if skeptic_speeches:
                md.append("## è´¨ç–‘è€…å‘è¨€æ±‡æ€»\n\n")
                for idx, sk in enumerate(skeptic_speeches, 1):
                    md.append(f"### è´¨ç–‘#{idx} (ç¬¬{sk['round']}è½®)\n\n")
                    md.append(f"**è´¨ç–‘è€…**: {sk['speaker']}\n")
                    if sk.get('target_expert'):
                        md.append(f"**é’ˆå¯¹**: {sk['target_expert']}\n")
                    md.append(f"\n{sk.get('speech', 'æ— ')}\n\n")
                md.append("---\n\n")
            
            # ---- å„è½®æ¬¡è®°å½• ----
            md.append("## å„è½®æ¬¡è®¨è®ºè®°å½•\n\n")
            for rn in sorted(all_speeches_by_round.keys()):
                sps = all_speeches_by_round[rn]
                md.append(f"### ç¬¬{rn}è½®è®¨è®º\n\n")
                md.append(f"**å‘è¨€æ•°**: {len(sps)}\n\n")
                for sp in sps:
                    if sp.get('is_skeptic') and sp.get('target_expert'):
                        md.append(f"**{sp['speaker']}** (è´¨ç–‘ -> {sp['target_expert']}):\n\n")
                    else:
                        md.append(f"**{sp['speaker']}**:\n\n")
                    md.append(f"{sp.get('speech', 'æ— ')[:800]}\n\n")
                md.append("---\n\n")
            
            # ---- å…±è¯†ä¸åˆ†æ­§ ----
            md.append("## å…±è¯†ä¸åˆ†æ­§\n\n")
            consensus_data = discussion_state.get('consensus_data', {})
            key_points = consensus_data.get('key_points', [])
            if key_points:
                md.append("### å…±è¯†ç‚¹\n\n")
                for i, p in enumerate(key_points, 1):
                    md.append(f"{i}. {p}\n")
                md.append("\n")
            divergences = consensus_data.get('divergences', [])
            if divergences:
                md.append("### åˆ†æ­§ç‚¹\n\n")
                for i, d in enumerate(divergences, 1):
                    md.append(f"{i}. {d}\n")
                md.append("\n")
            md.append(f"**æ•´ä½“å…±è¯†æ°´å¹³**: {consensus_level:.2f}\n\n---\n\n")
            
            # ---- æœ€ç»ˆæŠ¥å‘Š ----
            md.append("## æœ€ç»ˆæŠ¥å‘Šä¸è¡ŒåŠ¨å»ºè®®\n\n")
            if final_report:
                for i, ins in enumerate(final_report.get('key_insights', []), 1):
                    md.append(f"{i}. {ins}\n")
                md.append("\n")
                for i, rec in enumerate(final_report.get('action_recommendations', []), 1):
                    md.append(f"{i}. {rec}\n")
                md.append("\n")
            md.append("---\n*æ­¤æ–‡æ¡£ç”±åœ†æ¡Œè®¨è®ºç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œä¾›ç¬¬äºŒå±‚å®æ–½ä¸“å®¶æŒ‰ç›®å½•ç´¢å¼•æŸ¥é˜…ã€‚*\n")
            
            # ---- å†™å…¥ Markdownï¼ˆç¬¬ä¸€å±‚æ±‡æ€»ä¿å­˜åˆ° discuss/ï¼‰ ----
            md_filename = f"layer1_discussion_summary_{timestamp}.md"
            md_filepath = os.path.join(discuss_dir, md_filename)
            with open(md_filepath, 'w', encoding='utf-8') as f:
                f.write("".join(md))
            logger.info(f"ç”Ÿæˆç¬¬ä¸€å±‚æ±‡æ€»æ–‡æ¡£: {md_filepath}")
            
            # ---- JSON ç»“æ„åŒ–ç´¢å¼• ----
            json_index = {
                "document_type": "layer1_discussion_summary",
                "discussion_id": discussion_state.get('discussion_id', ''),
                "topic": query,
                "generated_at": datetime.now().isoformat(),
                "summary_md_file": md_filepath,
                "statistics": {
                    "total_rounds": total_rounds,
                    "total_speeches": total_speeches,
                    "participants_count": len(participants),
                    "consensus_level": consensus_level
                },
                "table_of_contents": {
                    "by_role": {
                        sp_name: {
                            "speech_count": len(sp_list),
                            "rounds": sorted(set(s['round'] for s in sp_list)),
                            "is_skeptic": any(s['is_skeptic'] for s in sp_list)
                        }
                        for sp_name, sp_list in all_speeches_by_speaker.items()
                    },
                    "by_round": {
                        str(rn): {
                            "speech_count": len(sp_list),
                            "speakers": [s['speaker'] for s in sp_list]
                        }
                        for rn, sp_list in all_speeches_by_round.items()
                    }
                },
                "consensus_data": {
                    "overall_level": consensus_level,
                    "key_points": key_points,
                    "divergences": divergences
                },
                "final_report": {
                    "key_insights": final_report.get('key_insights', []) if final_report else [],
                    "action_recommendations": final_report.get('action_recommendations', []) if final_report else []
                }
            }
            
            json_filename = f"layer1_discussion_index_{timestamp}.json"
            json_filepath = os.path.join(discuss_dir, json_filename)
            with open(json_filepath, 'w', encoding='utf-8') as f:
                json.dump(json_index, f, ensure_ascii=False, indent=2)
            logger.info(f"ç”Ÿæˆç¬¬ä¸€å±‚ç»“æ„åŒ–ç´¢å¼•: {json_filepath}")
            
            # æ›´æ–° discussion_state
            discussion_state['layer1_summary'] = {
                'md_file': md_filepath,
                'json_index_file': json_filepath,
                'relative_md_file': os.path.relpath(md_filepath, discussion_base_path),
                'relative_json_file': os.path.relpath(json_filepath, discussion_base_path),
                'timestamp': timestamp,
                'statistics': json_index['statistics'],
                'table_of_contents': json_index['table_of_contents']
            }
            
            return md_filepath
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆç¬¬ä¸€å±‚æ±‡æ€»æ–‡æ¡£å¤±è´¥: {e}", exc_info=True)
            return None

    def _save_discussion_state(self, discussion_base_path: str, state_data: dict):
        """ä¿å­˜ä¼šè®®çŠ¶æ€åˆ°JSONæ–‡ä»¶"""
        try:
            state_file = os.path.join(discussion_base_path, "discussion_state.json")
            state_data['updated_at'] = datetime.now().isoformat()
            with open(state_file, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, ensure_ascii=False, indent=2)
            logger.info(f"ä¿å­˜ä¼šè®®çŠ¶æ€: {state_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜ä¼šè®®çŠ¶æ€å¤±è´¥: {e}")

    def _load_discussion_state(self, discussion_base_path: str) -> Optional[dict]:
        """ä»æ–‡ä»¶åŠ è½½ä¼šè®®çŠ¶æ€ï¼›è‹¥æ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥åˆ™è¿”å› Noneã€‚"""
        try:
            state_file = os.path.join(discussion_base_path, "discussion_state.json")
            if not os.path.exists(state_file):
                return None
            with open(state_file, 'r', encoding='utf-8') as f:
                state = json.load(f)
            logger.info(f"å·²ä»æ–‡ä»¶åŠ è½½è®¨è®ºçŠ¶æ€: {state_file}, topic={state.get('topic', '')[:80]}...")
            return state
        except Exception as e:
            logger.warning(f"åŠ è½½è®¨è®ºçŠ¶æ€å¤±è´¥: {e}")
            return None

    def _build_speech_search_index(self, discussion_base_path: str) -> None:
        """
        å¯¹å‘è¨€å®Œæˆçš„ä»»åŠ¡å»ºç«‹ä¸Šä¸‹æ–‡æœç´¢ç›®å½•ï¼ˆspeech_index.jsonï¼‰ï¼Œ
        ä¾¿äºæŒ‰å†…å®¹æŸ¥è¯¢å“ªä¸ªæ™ºèƒ½ä½“åœ¨å“ªæ¬¡å‘è¨€ä¸­è¯´äº†ä»€ä¹ˆã€‚
        """
        try:
            index_entries: List[Dict[str, Any]] = []
            discuss_dir = os.path.join(discussion_base_path, "discuss")
            impl_dir = os.path.join(discussion_base_path, "implement")
            conc_dir = os.path.join(discussion_base_path, "concretization")
            state = self._load_discussion_state(discussion_base_path)
            # ç¬¬ä¸€å±‚ï¼šä» state.rounds[].speeches[] æˆ– discuss/*.md
            if state:
                for r in state.get("rounds", []):
                    rn = r.get("round_number", 0)
                    for sp in r.get("speeches", []):
                        speaker = sp.get("speaker", "æœªçŸ¥")
                        rel = sp.get("relative_file_path") or sp.get("file_path", "")
                        if rel and not os.path.isabs(rel):
                            path = os.path.join(discussion_base_path, rel)
                        else:
                            path = sp.get("file_path", "")
                        if path and os.path.exists(path):
                            try:
                                with open(path, "r", encoding="utf-8") as f:
                                    text = f.read()
                                preview = (text[:200] + "â€¦") if len(text) > 200 else text
                            except Exception:
                                preview = ""
                            index_entries.append({
                                "layer": 1,
                                "speaker": speaker,
                                "round": rn,
                                "path": os.path.relpath(path, discussion_base_path),
                                "preview": preview,
                            })
            for d, layer in [(discuss_dir, 1), (impl_dir, 2), (conc_dir, 3)]:
                if not os.path.isdir(d):
                    continue
                for fn in os.listdir(d):
                    if not fn.endswith(".md"):
                        continue
                    path = os.path.join(d, fn)
                    rel = os.path.relpath(path, discussion_base_path)
                    speaker = fn.replace(".md", "").replace("impl_expert_", "").replace("_proposal_", " ")
                    if layer == 1 and state:
                        for r in state.get("rounds", []):
                            for sp in r.get("speeches", []):
                                if rel in (sp.get("relative_file_path") or "", sp.get("file_path") or ""):
                                    speaker = sp.get("speaker", speaker)
                                    break
                    try:
                        with open(path, "r", encoding="utf-8") as f:
                            text = f.read()
                        preview = (text[:200] + "â€¦") if len(text) > 200 else text
                    except Exception:
                        preview = ""
                    if not any(e.get("path") == rel for e in index_entries):
                        index_entries.append({
                            "layer": layer,
                            "speaker": speaker,
                            "round": None,
                            "path": rel,
                            "preview": preview,
                        })
            out_path = os.path.join(discussion_base_path, "speech_index.json")
            with open(out_path, "w", encoding="utf-8") as f:
                json.dump({"updated_at": datetime.now().isoformat(), "entries": index_entries}, f, ensure_ascii=False, indent=2)
            logger.info(f"å·²ç”Ÿæˆå‘è¨€æ£€ç´¢ç´¢å¼•: {out_path}, å…± {len(index_entries)} æ¡")
        except Exception as e:
            logger.warning(f"æ„å»ºå‘è¨€æ£€ç´¢ç´¢å¼•å¤±è´¥: {e}", exc_info=True)

    def modify_agent_speech(
        self,
        discussion_id: str,
        speaker_name: Optional[str] = None,
        layer: Optional[int] = None,
        user_content: str = "",
    ) -> None:
        """
        ä¿®æ”¹æŒ‡å®šä»»åŠ¡ä¸­æŸæ™ºèƒ½ä½“çš„å‘è¨€å†…å®¹ï¼›è‹¥ä¿®æ”¹ç¬¬ä¸€å±‚åˆ™çº§è”é‡è·‘ç¬¬äºŒã€ä¸‰å±‚ï¼Œè‹¥ä¿®æ”¹ç¬¬äºŒå±‚åˆ™çº§è”é‡è·‘ç¬¬ä¸‰å±‚ã€‚
        """
        discussion_base_path = os.path.join("discussion", discussion_id)
        discussion_state = self._load_discussion_state(discussion_base_path)
        if not discussion_state:
            logger.warning(f"æœªæ‰¾åˆ°ä»»åŠ¡: {discussion_id}")
            return

        def _speaker_match(name: str, target: Optional[str]) -> bool:
            if not (name and target):
                return False
            n, t = (name or "").strip(), (target or "").strip()
            if not t:
                return False
            return t in n or n in t or n.replace("ä¸“å®¶_", "") == t.replace("ä¸“å®¶_", "")

        modified_layer: Optional[int] = None
        query = discussion_state.get("topic", "")

        # ç¬¬ä¸€å±‚ï¼šåœ¨ rounds[].speeches[] ä¸­æŒ‰ speaker åŒ¹é…å¹¶å†™å›æ–‡ä»¶ä¸ state
        if layer in (None, 1):
            for round_data in discussion_state.get("rounds", []):
                for speech in round_data.get("speeches", []):
                    if not _speaker_match(speech.get("speaker", ""), speaker_name):
                        continue
                    fp = speech.get("file_path") or os.path.join(discussion_base_path, speech.get("relative_file_path", ""))
                    if not os.path.isabs(fp):
                        fp = os.path.join(discussion_base_path, fp)
                    if not fp:
                        continue
                    try:
                        with open(fp, "w", encoding="utf-8") as f:
                            f.write(user_content)
                        speech["speech"] = user_content
                        jpath = speech.get("json_file_path") or (fp.replace(".md", ".json") if fp.endswith(".md") else "")
                        if jpath and not os.path.isabs(jpath):
                            jpath = os.path.join(discussion_base_path, jpath)
                        if jpath and os.path.exists(jpath):
                            with open(jpath, "r", encoding="utf-8") as f:
                                j = json.load(f)
                            j["speech"] = user_content
                            with open(jpath, "w", encoding="utf-8") as f:
                                json.dump(j, f, ensure_ascii=False, indent=2)
                    except Exception as e:
                        logger.warning(f"å†™å›ç¬¬ä¸€å±‚å‘è¨€æ–‡ä»¶å¤±è´¥: {e}")
                    modified_layer = 1
                    break
                if modified_layer == 1:
                    break

        # ç¬¬äºŒå±‚ï¼šåœ¨ layer2.speeches[] ä¸­æŒ‰ speaker åŒ¹é…å¹¶å†™å› implement ä¸‹æ–‡ä»¶
        if modified_layer is None and layer in (None, 2):
            for s in discussion_state.get("layer2", {}).get("speeches", []):
                if not _speaker_match(s.get("speaker", ""), speaker_name):
                    continue
                rel = s.get("relative_file_path", "")
                if not rel:
                    continue
                full = os.path.join(discussion_base_path, rel)
                try:
                    with open(full, "w", encoding="utf-8") as f:
                        f.write(user_content)
                except Exception as e:
                    logger.warning(f"å†™å›ç¬¬äºŒå±‚å‘è¨€æ–‡ä»¶å¤±è´¥: {e}")
                modified_layer = 2
                break

        if modified_layer is None:
            logger.warning(f"æœªæ‰¾åˆ°åŒ¹é…çš„å‘è¨€: discussion_id={discussion_id}, speaker={speaker_name}, layer={layer}")
            return

        self._save_discussion_state(discussion_base_path, discussion_state)

        if modified_layer == 1:
            discussion_state.pop("implementation_layer", None)
            discussion_state.pop("concretization_layer", None)
            discussion_state.pop("layer2", None)
            self._save_discussion_state(discussion_base_path, discussion_state)
            final_report = discussion_state.get("final_report", {})
            decision_output = self._convert_to_decision_output(discussion_state, final_report, query)
            self._run_implementation_layer(decision_output, discussion_state, discussion_base_path)
            self._run_concretization_layer(discussion_base_path, discussion_state.get("discussion_id", ""))
            discussion_state["concretization_layer"] = {"status": "completed", "timestamp": datetime.now().isoformat()}
            self._save_discussion_state(discussion_base_path, discussion_state)
        elif modified_layer == 2:
            discussion_state.pop("concretization_layer", None)
            self._save_discussion_state(discussion_base_path, discussion_state)
            self._run_concretization_layer(discussion_base_path, discussion_state.get("discussion_id", ""))
            discussion_state["concretization_layer"] = {"status": "completed", "timestamp": datetime.now().isoformat()}
            self._save_discussion_state(discussion_base_path, discussion_state)

        self._build_speech_search_index(discussion_base_path)
    
    def _make_config_json_serializable(self, obj: Any) -> Any:
        """å°†å¯èƒ½å«é JSON ç±»å‹çš„é…ç½®è½¬ä¸ºå¯åºåˆ—åŒ–ç»“æ„ï¼ˆå¦‚ DomainExpert ç­‰å¯¹è±¡ï¼‰ã€‚"""
        if obj is None or isinstance(obj, (bool, int, float)):
            return obj
        if isinstance(obj, str):
            return obj
        if isinstance(obj, dict):
            return {k: self._make_config_json_serializable(v) for k, v in obj.items()}
        if isinstance(obj, (list, tuple)):
            return [self._make_config_json_serializable(x) for x in obj]
        # éåŸºæœ¬ç±»å‹ï¼šä¼˜å…ˆå– name/role ç­‰æè¿°ï¼Œå¦åˆ™ç”¨å­—ç¬¦ä¸²è¡¨ç¤º
        if hasattr(obj, 'name') and hasattr(obj, 'role'):
            return {"name": getattr(obj, 'name', None), "role": getattr(obj, 'role', None), "domain": getattr(obj, 'domain', None)}
        if hasattr(obj, '__dict__'):
            return self._make_config_json_serializable({k: v for k, v in obj.__dict__.items() if not k.startswith('_')})
        return str(obj)

    def _save_agent_config(self, discussion_base_path: str, agent_name: str, agent_config: dict):
        """
        ä¿å­˜æ™ºèƒ½ä½“é…ç½®åˆ° roles ç›®å½•
        
        Args:
            discussion_base_path: è®¨è®ºæ–‡ä»¶å¤¹è·¯å¾„
            agent_name: æ™ºèƒ½ä½“åç§°
            agent_config: æ™ºèƒ½ä½“é…ç½®å­—å…¸ï¼ˆå¯èƒ½å« DomainExpert ç­‰å¯¹è±¡ï¼Œä¼šå…ˆè½¬ä¸ºå¯åºåˆ—åŒ–ï¼‰
        """
        try:
            config_serializable = self._make_config_json_serializable(agent_config)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_agent_name = re.sub(r'[^\w\u4e00-\u9fa5]', '_', agent_name)
            roles_dir = os.path.join(discussion_base_path, "roles")
            os.makedirs(roles_dir, exist_ok=True)
            json_filename = f"{safe_agent_name}_{timestamp}.json"
            json_filepath = os.path.join(roles_dir, json_filename)
            with open(json_filepath, 'w', encoding='utf-8') as f:
                json.dump(config_serializable, f, ensure_ascii=False, indent=2)
            logger.info(f"ä¿å­˜æ™ºèƒ½ä½“é…ç½®: {json_filepath}")
            return json_filepath
        except Exception as e:
            logger.error(f"ä¿å­˜æ™ºèƒ½ä½“é…ç½®å¤±è´¥: {e}")
            return None

    def chat_with_discussion(self, user_id, session_id, query, file_path, discussion_id):
        """
        åœ†æ¡Œè®¨è®ºå¤´è„‘é£æš´ä¼šè®®ç³»ç»Ÿ - å¯åŠ¨æ–°ä»»åŠ¡
        æ”¯æŒå¤šæ™ºèƒ½ä½“åä½œçš„æ·±åº¦è®¨è®ºå’Œå†³ç­–
        
        æ³¨æ„ï¼šæ„å›¾è¯†åˆ«å·²ç§»è‡³ control_chat.pyï¼Œæ­¤æ–¹æ³•åªè´Ÿè´£å¯åŠ¨æ–°ä»»åŠ¡

        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID  
            query: ç”¨æˆ·æŸ¥è¯¢/è®¨è®ºä¸»é¢˜
            file_path: æ–‡ä»¶è·¯å¾„
            discussion_id: ä¼šè®®ID
        """
        try:
            # ç”Ÿæˆå”¯ä¸€ID
            _id = f"roundtable-{int(time.time())}"

            # æ·»åŠ åˆå§‹æ—¥å¿—
            logger.info(f"å¼€å§‹åœ†æ¡Œä¼šè®®å¤„ç†: user_id={user_id}, session_id={session_id}, query={query[:100] if query else 'None'}")
            logger.info("ğŸš€ æ­£åœ¨å¯åŠ¨åœ†æ¡Œè®¨è®ºç³»ç»Ÿ...")
            
            discussion_base_path = os.path.join("discussion", discussion_id)
            
            # åˆ›å»ºæ–‡ä»¶å¤¹ç»“æ„ï¼šdiscuss/ ç¬¬ä¸€å±‚è®¨è®ºå‘è¨€ï¼›implement/ ç¬¬äºŒå±‚å®æ–½æ–¹æ¡ˆï¼›concretization/ ç¬¬ä¸‰å±‚å…·åƒåŒ–
            os.makedirs(os.path.join(discussion_base_path, "discuss"), exist_ok=True)
            os.makedirs(os.path.join(discussion_base_path, "implement"), exist_ok=True)
            os.makedirs(os.path.join(discussion_base_path, "concretization"), exist_ok=True)
            os.makedirs(os.path.join(discussion_base_path, "code"), exist_ok=True)
            os.makedirs(os.path.join(discussion_base_path, "images"), exist_ok=True)
            os.makedirs(os.path.join(discussion_base_path, "pro"), exist_ok=True)
            os.makedirs(os.path.join(discussion_base_path, "files"), exist_ok=True)
            os.makedirs(os.path.join(discussion_base_path, "roles"), exist_ok=True)
            
            logger.info(f"åˆ›å»ºåœ†æ¡Œä¼šè®®æ–‡ä»¶å¤¹: {discussion_base_path}")
            
            # é‡å¯æ—¶ä»æ–‡ä»¶è¯»å–çŠ¶æ€ä¸ä¸»é¢˜ï¼Œé¿å…ç”¨å½“å‰ç”¨æˆ·è¾“å…¥è¦†ç›–å·²æœ‰ä¸»é¢˜
            discussion_state = self._load_discussion_state(discussion_base_path)
            if discussion_state is not None:
                topic_for_session = discussion_state.get("topic") or query
                logger.info(f"æ¢å¤å·²æœ‰ä»»åŠ¡ï¼Œä½¿ç”¨æ–‡ä»¶ä¸­ä¸»é¢˜: {topic_for_session[:80] if topic_for_session else 'None'}...")
            else:
                topic_for_session = query
                discussion_state = {
                    "discussion_id": discussion_id,
                    "topic": query,
                    "status": "initializing",
                    "created_at": datetime.now().isoformat(),
                    "updated_at": datetime.now().isoformat(),
                    "current_round": 0,
                    "max_rounds": 5,
                    "participants": [],
                    "rounds": [],
                    "consensus_data": {
                        "overall_level": 0.0,
                        "key_points": [],
                        "divergences": []
                    },
                    "file_path": file_path
                }
                self._save_discussion_state(discussion_base_path, discussion_state)
            
            # ä»…æ–°å»ºä»»åŠ¡æ—¶å†™å…¥æ•°æ®åº“è®°å½•
            if session_id and discussion_state.get("status") == "initializing":
                try:
                    cSingleSqlite.insert_discussion_task_record(
                        session_id=session_id,
                        discussion_id=discussion_id,
                        user_id=user_id,
                        task_status='active'
                    )
                    logger.info(f"ä¿å­˜ä»»åŠ¡è®°å½•æˆåŠŸ: session_id={session_id}, discussion_id={discussion_id}")
                except Exception as e:
                    logger.warning(f"ä¿å­˜ä»»åŠ¡è®°å½•å¤±è´¥: {e}")

            # åˆå§‹åŒ–LLMå®ä¾‹
            llm_instance = get_chat_tongyi()
            print("LLMå®ä¾‹åˆå§‹åŒ–å®Œæˆ")
            print(discussion_id)
            # åˆ›å»ºåœ†æ¡Œè®¨è®ºç³»ç»Ÿå®ä¾‹
            discussion_system = RoundtableDiscussion(llm_instance=llm_instance, discussion_id=discussion_id)

            # å¯åŠ¨è®¨è®ºç³»ç»Ÿ
            initialization_complete = False
            initialization_error = False
            
            try:
                is_resuming = discussion_state is not None and discussion_state.get("status") != "initializing"
                for init_step in discussion_system.start_discussion(topic_for_session, is_resuming=is_resuming):
                    step_type = init_step.get("step")
                    
                    # å¤„ç†é”™è¯¯æ­¥éª¤ï¼ˆä¼˜å…ˆå¤„ç†ï¼‰
                    if step_type == "error":
                        logger.error(f"âŒ {init_step['message']}ï¼Œé”™è¯¯è¯¦æƒ…: {init_step.get('error_details', 'æœªçŸ¥é”™è¯¯')}")
                        initialization_error = True
                        return False
                    
                    # å¤„ç†å„ä¸ªåˆå§‹åŒ–æ­¥éª¤
                    if step_type == "init_start":
                        logger.info(f"åˆå§‹åŒ–å¼€å§‹: {init_step['message']}")
                    
                    elif step_type == "scholar_analysis":
                        logger.info(f"å­¦è€…åˆ†æ: {init_step['message']}")
                    
                    elif step_type == "scholar_result":
                        # ä¿å­˜å­¦è€…åˆ†æç»“æœåˆ°æ–‡ä»¶
                        task_analysis = init_step.get("task_analysis")
                        if task_analysis:
                            core_analysis = task_analysis.get('core_analysis', {})
                            domain_analysis = task_analysis.get('domain_analysis', {})
                            participant_analysis = task_analysis.get('participant_analysis', {})
                            risk_analysis = task_analysis.get('risk_analysis', {})
                            
                            # ç¬¬ä¸€å±‚è®¨è®ºç»“æœä¿å­˜åˆ° discuss/
                            discuss_dir = os.path.join(discussion_base_path, "discuss")
                            os.makedirs(discuss_dir, exist_ok=True)
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            json_filename = f"scholar_analysis_{timestamp}.json"
                            json_filepath = os.path.join(discuss_dir, json_filename)
                            
                            try:
                                scholar_analysis_data = {
                                    "analysis_time": datetime.now().isoformat(),
                                    "topic": query,
                                    "core_analysis": core_analysis,
                                    "domain_analysis": domain_analysis,
                                    "participant_analysis": participant_analysis,
                                    "risk_analysis": risk_analysis,
                                    "full_task_analysis": task_analysis
                                }
                                
                                with open(json_filepath, 'w', encoding='utf-8') as f:
                                    json.dump(scholar_analysis_data, f, ensure_ascii=False, indent=2)
                                logger.info(f"ä¿å­˜å­¦è€…åˆ†æç»“æœåˆ°JSONæ–‡ä»¶: {json_filepath}")
                            except Exception as e:
                                logger.error(f"ä¿å­˜å­¦è€…åˆ†æJSONæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
                            
                            # ä¿å­˜åˆ°Markdownæ–‡ä»¶ï¼ˆå¯è¯»æ ¼å¼ï¼‰
                            md_filename = f"scholar_analysis_{timestamp}.md"
                            md_filepath = os.path.join(discuss_dir, md_filename)
                            
                            try:
                                md_content = f"""# ğŸ“š å­¦è€…åˆ†æç»“æœ

**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ¯ æ ¸å¿ƒé—®é¢˜

{core_analysis.get('core_problem', 'æœªåˆ†æ')}

## ğŸ“ é—®é¢˜åˆ†è§£

""" + "\n".join(f"{i+1}. {problem}" for i, problem in enumerate(core_analysis.get('sub_problems', []))) + f"""

## â±ï¸ é¡¹ç›®è¯„ä¼°

| ç»´åº¦ | å€¼ |
|------|-----|
| é¢„ä¼°æ—¶é—´ | {core_analysis.get('time_estimate', 'æœªé¢„ä¼°')} |
| å¤æ‚åº¦ | {core_analysis.get('complexity_level', 'æœªè¯„ä¼°')} |

## ğŸ¢ é¢†åŸŸåˆ†æ

- **ä¸»è¦é¢†åŸŸ**: {domain_analysis.get('primary_domain', 'æœªç¡®å®š')}
- **ç›¸å…³é¢†åŸŸ**: {', '.join(domain_analysis.get('secondary_domains', []))}

## ğŸ‘¥ æ¨èä¸“å®¶è§’è‰² ({len(participant_analysis.get('recommended_roles', []))}ä¸ª)

""" + "\n".join(f"{i+1}. **{role.get('role', 'æœªçŸ¥è§’è‰²')}** - {role.get('reason', 'éœ€è¦ä¸“ä¸šçŸ¥è¯†')}" 
                 for i, role in enumerate(participant_analysis.get('recommended_roles', []))) + f"""

## âš ï¸ é£é™©åˆ†æ

### é£é™©å› ç´  ({len(risk_analysis.get('risk_factors', []))} ä¸ª)

""" + "\n".join(f"- {risk}" for risk in risk_analysis.get('risk_factors', [])) + f"""

### ç¼“è§£ç­–ç•¥ ({len(risk_analysis.get('mitigation_strategies', []))} æ¡)

""" + "\n".join(f"- {strategy}" for strategy in risk_analysis.get('mitigation_strategies', [])) + "\n"
                                
                                with open(md_filepath, 'w', encoding='utf-8') as f:
                                    f.write(md_content)
                                logger.info(f"ä¿å­˜å­¦è€…åˆ†æç»“æœåˆ°Markdownæ–‡ä»¶: {md_filepath}")
                            except Exception as e:
                                logger.error(f"ä¿å­˜å­¦è€…åˆ†æMarkdownæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
                            
                            # æ›´æ–°discussion_stateï¼Œä¿å­˜æ–‡ä»¶è·¯å¾„
                            try:
                                discussion_state['scholar_analysis'] = {
                                    "json_file": json_filepath,
                                    "md_file": md_filepath,
                                    "relative_json_file": os.path.relpath(json_filepath, discussion_base_path),
                                    "relative_md_file": os.path.relpath(md_filepath, discussion_base_path),
                                    "timestamp": timestamp,
                                    "datetime": datetime.now().isoformat()
                                }
                                discussion_state['updated_at'] = datetime.now().isoformat()
                                self._save_discussion_state(discussion_base_path, discussion_state)
                                logger.info(f"å·²æ›´æ–°discussion_state.jsonï¼Œæ·»åŠ å­¦è€…åˆ†ææ–‡ä»¶è·¯å¾„")
                            except Exception as e:
                                logger.error(f"æ›´æ–°discussion_stateå¤±è´¥: {e}", exc_info=True)
                            
                            # åªåœ¨å‰ç«¯æ˜¾ç¤ºæ–‡ä»¶è·¯å¾„
                            abs_md_filepath = os.path.abspath(md_filepath)
                            abs_json_filepath = os.path.abspath(json_filepath)
                            
                            # è®°å½•å­¦è€…åˆ†æå®Œæˆä¿¡æ¯
                            logger.info(f"ğŸ“š å­¦è€…åˆ†æå®Œæˆï¼Œåˆ†æç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶ï¼š{abs_md_filepath}")
                            
                            # JSONæ–‡ä»¶è·¯å¾„ä¸å‘é€ç»™å‰ç«¯ï¼ˆä¸ç”Ÿæˆchunkï¼‰
                    
                    elif step_type == "topic_profiling":
                        logger.info(f"è¯é¢˜ç”»åƒ: {init_step['message']}")
                    
                    elif step_type == "topic_profiling_llm":
                        logger.info(f"è¯é¢˜ç”»åƒLLM: {init_step['message']}")
                    
                    elif step_type == "topic_profiling_parsing":
                        logger.info(f"è¯é¢˜ç”»åƒè§£æ: {init_step['message']}")
                    
                    elif step_type == "topic_profiling_fallback":
                        logger.info(f"è¯é¢˜ç”»åƒå›é€€: {init_step['message']}")
                    
                    elif step_type == "topic_profile_complete":
                        # è®°å½•è¯é¢˜ç”»åƒä¿¡æ¯
                        topic_profile = init_step.get("topic_profile")
                        if topic_profile:
                            characteristics = topic_profile.get('topic_characteristics', {})
                            strategy = topic_profile.get('discussion_strategy', {})
                            logger.info(f"ğŸ¨ è¯é¢˜ç”»åƒå®Œæˆ - èŒƒå›´: {characteristics.get('scope', 'æœªç¡®å®š')}, ç´§æ€¥æ€§: {characteristics.get('urgency', 'æœªç¡®å®š')}, å½±å“ç¨‹åº¦: {characteristics.get('impact', 'æœªç¡®å®š')}")
                    
                    elif step_type == "agent_creation_start":
                        logger.info(f"æ™ºèƒ½ä½“åˆ›å»ºå¼€å§‹: {init_step['message']}")
                    
                    elif step_type == "agent_created":
                        # è®°å½•åˆ›å»ºçš„æ™ºèƒ½ä½“
                        agent_name = init_step.get('agent_name', 'unknown')
                        agent_role = init_step.get('agent_role', 'æœªçŸ¥')
                        agent_config = init_step.get('agent_config', None)
                        
                        logger.info(f"æ™ºèƒ½ä½“åˆ›å»º: {init_step.get('message', '')} - è§’è‰²: {agent_role}, èŒè´£: {init_step.get('description', 'æœªæŒ‡å®š')}")
                        
                        # ä¿å­˜æ™ºèƒ½ä½“é…ç½®åˆ° roles ç›®å½•
                        if agent_config:
                            config_filepath = self._save_agent_config(discussion_base_path, agent_name, agent_config)
                            if config_filepath:
                                logger.info(f"æ™ºèƒ½ä½“é…ç½®å·²ä¿å­˜: {config_filepath}")
                    
                    elif step_type == "agent_creation_complete":
                        participants = init_step.get('participants', [])
                        logger.info(f"âœ… æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆï¼Œæ€»è®¡ {len(participants)} ä¸ªæ™ºèƒ½ä½“è§’è‰²å·²å°±ä½: {participants}")
                    
                    elif step_type == "agent_creation_error":
                        logger.warning(f"æ™ºèƒ½ä½“åˆ›å»ºé”™è¯¯: {init_step.get('message', 'æ™ºèƒ½ä½“åˆ›å»ºé‡åˆ°é—®é¢˜')}")
                    
                    elif step_type == "moderator_opening":
                        logger.info(f"ä¸»æŒäººå¼€åœº: {init_step['message']}")
                    
                    elif step_type == "meeting_opened":
                        # ä¿å­˜ä¸»æŒäººå¼€åœºç™½åˆ°æ–‡ä»¶
                        opening_speech = init_step.get('opening_speech', 'ä¼šè®®å¼€å§‹')
                        meeting_message = init_step.get('message', 'ä¼šè®®å¼€å§‹')
                        
                        # ç¬¬ä¸€å±‚è®¨è®ºç»“æœä¿å­˜åˆ° discuss/
                        discuss_dir = os.path.join(discussion_base_path, "discuss")
                        os.makedirs(discuss_dir, exist_ok=True)
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        md_filename = f"moderator_opening_{timestamp}.md"
                        md_filepath = os.path.join(discuss_dir, md_filename)
                        
                        try:
                            md_content = f"""# ğŸ›ï¸ ä¸»æŒäººå¼€åœºç™½

**ä¼šè®®æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ä¼šè®®ä¿¡æ¯

{meeting_message}

## å¼€åœºç™½å†…å®¹

{opening_speech}
"""
                            
                            with open(md_filepath, 'w', encoding='utf-8') as f:
                                f.write(md_content)
                            logger.info(f"ä¿å­˜ä¸»æŒäººå¼€åœºç™½åˆ°æ–‡ä»¶: {md_filepath}")
                        except Exception as e:
                            logger.error(f"ä¿å­˜ä¸»æŒäººå¼€åœºç™½æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
                        
                        # ä¿å­˜åˆ°JSONæ–‡ä»¶ï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰
                        json_filename = f"moderator_opening_{timestamp}.json"
                        json_filepath = os.path.join(discuss_dir, json_filename)
                        
                        try:
                            opening_data = {
                                "datetime": datetime.now().isoformat(),
                                "meeting_message": meeting_message,
                                "opening_speech": opening_speech,
                                "moderator": "ä¸»æŒäºº"
                            }
                            
                            with open(json_filepath, 'w', encoding='utf-8') as f:
                                json.dump(opening_data, f, ensure_ascii=False, indent=2)
                            logger.info(f"ä¿å­˜ä¸»æŒäººå¼€åœºç™½åˆ°JSONæ–‡ä»¶: {json_filepath}")
                        except Exception as e:
                            logger.error(f"ä¿å­˜ä¸»æŒäººå¼€åœºç™½JSONæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
                        
                        # æ›´æ–°discussion_stateï¼Œä¿å­˜æ–‡ä»¶è·¯å¾„
                        try:
                            discussion_state['moderator_opening'] = {
                                "md_file": md_filepath,
                                "json_file": json_filepath,
                                "relative_md_file": os.path.relpath(md_filepath, discussion_base_path),
                                "relative_json_file": os.path.relpath(json_filepath, discussion_base_path),
                                "timestamp": timestamp,
                                "datetime": datetime.now().isoformat()
                            }
                            discussion_state['updated_at'] = datetime.now().isoformat()
                            self._save_discussion_state(discussion_base_path, discussion_state)
                            logger.info(f"å·²æ›´æ–°discussion_state.jsonï¼Œæ·»åŠ ä¸»æŒäººå¼€åœºæ–‡ä»¶è·¯å¾„")
                        except Exception as e:
                            logger.error(f"æ›´æ–°discussion_stateå¤±è´¥: {e}", exc_info=True)
                        
                        # åªåœ¨å‰ç«¯æ˜¾ç¤ºæ–‡ä»¶è·¯å¾„
                        abs_md_filepath = os.path.abspath(md_filepath)
                        abs_json_filepath = os.path.abspath(json_filepath)
                        
                        # è®°å½•ä¸»æŒäººå¼€åœºç™½ä¿¡æ¯
                        logger.info(f"ğŸ›ï¸ {meeting_message}ï¼Œä¸»æŒäººå¼€åœºç™½å·²ä¿å­˜åˆ°æ–‡ä»¶ï¼š{abs_md_filepath}")
                        
                        # JSONæ–‡ä»¶è·¯å¾„ä¸å‘é€ç»™å‰ç«¯ï¼ˆä¸ç”Ÿæˆchunkï¼‰
                    
                    elif step_type == "discussion_ready":
                        participants = init_step.get('participants', [])
                        logger.info(f"ğŸ¯ {init_step.get('message', '')} - æœ€ç»ˆå‚ä¸è€…é˜µå®¹ ({len(participants)}äºº): {participants}")
                        initialization_complete = True
                        
                        # æ›´æ–°ä¼šè®®çŠ¶æ€ - åˆå§‹åŒ–å®Œæˆ
                        discussion_state['status'] = 'active'
                        discussion_state['participants'] = participants
                        self._save_discussion_state(discussion_base_path, discussion_state)
                    
                    else:
                        # æœªçŸ¥æ­¥éª¤ï¼Œè®°å½•æ—¥å¿—ä½†ä¸ä¸­æ–­æµç¨‹
                        # import logging
                        logging.warning(f"æœªçŸ¥çš„åˆå§‹åŒ–æ­¥éª¤: {step_type}, æ¶ˆæ¯: {init_step.get('message', '')}")
                        if init_step.get("message"):
                            logger.info(f"âš ï¸ {init_step['message']}")
                
            except Exception as e:
                logger.error(f"åˆå§‹åŒ–è®¨è®ºç³»ç»Ÿæ—¶å‡ºé”™: {str(e)}", exc_info=True)
                logger.error(f"âŒ åˆå§‹åŒ–è®¨è®ºç³»ç»Ÿå¤±è´¥: {str(e)}")
                initialization_error = True
                return False
            
            # æ£€æŸ¥åˆå§‹åŒ–æ˜¯å¦æˆåŠŸå®Œæˆ
            if initialization_error or not initialization_complete:
                logger.warning("âš ï¸ è®¨è®ºç³»ç»Ÿåˆå§‹åŒ–æœªå®Œæˆï¼Œæ— æ³•ç»§ç»­è®¨è®º")
                return False

            # è®¾ç½®è®¨è®ºè½®æ¬¡å‚æ•°
            round_number = 1
            max_rounds = discussion_state.get('max_rounds', 5) if discussion_state else 5
            max_rounds = 1
            while round_number <= max_rounds:
                logger.info(f"ğŸ”„ ç¬¬ {round_number} è½®è®¨è®ºå¼€å§‹")

                # æœ¬è½®å·²å‘è¨€çš„æ™ºèƒ½ä½“ï¼ˆé‡å¯æ—¶ä»çŠ¶æ€æ¢å¤ï¼Œé¿å…é‡å¤å‘è¨€ï¼‰
                already_spoken = set()
                rounds_list = discussion_state.get("rounds") or []
                if round_number <= len(rounds_list):
                    round_data = rounds_list[round_number - 1]
                    already_spoken = {s.get("speaker") for s in round_data.get("speeches", []) if s.get("speaker")}
                if already_spoken:
                    logger.info(f"ç¬¬ {round_number} è½®å·²å‘è¨€æ™ºèƒ½ä½“ï¼ˆå°†è·³è¿‡ï¼‰: {already_spoken}")

                # æ‰§è¡Œä¸€è½®è®¨è®º
                round_complete = False
                has_speeches = False
                
                for step_result in discussion_system.conduct_discussion_round(round_number, already_spoken_speakers=already_spoken):
                    if "error" in step_result:
                        logger.error(f"âŒ è®¨è®ºè½®æ¬¡é”™è¯¯: {step_result['error']}")
                        return False

                    step_type = step_result.get("step")
                    
                    # è®°å½•æ˜¯å¦æœ‰å‘è¨€
                    if step_type == "speech":
                        has_speeches = True
                    
                    # å¤„ç†è­¦å‘Šä¿¡æ¯
                    if step_type == "warning":
                        logger.warning(f"âš ï¸ {step_result.get('message', 'è­¦å‘Š')}")
                        continue
                    
                    # å¤„ç†å‘è¨€é”™è¯¯
                    if step_type == "speech_error":
                        logger.warning(f"âš ï¸ {step_result.get('message', 'å‘è¨€å‡ºé”™')}")
                        continue

                    if step_type == "round_start":
                        logger.info(f"ğŸ“ {step_result.get('message', f'å¼€å§‹ç¬¬{round_number}è½®è®¨è®º')}")

                    elif step_type == "coordination":
                        # ä¿å­˜åè°ƒè€…ç»“æœåˆ°æ–‡ä»¶
                        content = step_result.get('content', {})
                        coordination_result = content.get('coordination_result', {}) if isinstance(content, dict) else str(content)
                        
                        # æå–åè°ƒè®¡åˆ’å†…å®¹
                        coordination_plan = ""
                        if isinstance(coordination_result, dict):
                            coordination_plan = coordination_result.get('coordination_plan', str(coordination_result))
                        else:
                            coordination_plan = str(coordination_result)
                        
                        # ç¬¬ä¸€å±‚è®¨è®ºç»“æœä¿å­˜åˆ° discuss/
                        discuss_dir = os.path.join(discussion_base_path, "discuss")
                        os.makedirs(discuss_dir, exist_ok=True)
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        md_filename = f"facilitator_coordination_round{round_number}_{timestamp}.md"
                        md_filepath = os.path.join(discuss_dir, md_filename)
                        
                        try:
                            md_content = f"""# ğŸ‘¨â€âš–ï¸ åè°ƒè€…å‘è¨€å®‰æ’

**è½®æ¬¡**: ç¬¬ {round_number} è½®è®¨è®º
**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## åè°ƒè®¡åˆ’

{coordination_plan}
"""
                            
                            with open(md_filepath, 'w', encoding='utf-8') as f:
                                f.write(md_content)
                            logger.info(f"ä¿å­˜åè°ƒè€…ç»“æœåˆ°æ–‡ä»¶: {md_filepath}")
                        except Exception as e:
                            logger.error(f"ä¿å­˜åè°ƒè€…ç»“æœæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
                        
                        # ä¿å­˜åˆ°JSONæ–‡ä»¶ï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰
                        json_filename = f"facilitator_coordination_round{round_number}_{timestamp}.json"
                        json_filepath = os.path.join(discuss_dir, json_filename)
                        
                        try:
                            coordination_data = {
                                "round_number": round_number,
                                "datetime": datetime.now().isoformat(),
                                "coordination_result": coordination_result if isinstance(coordination_result, dict) else {"plan": coordination_result},
                                "coordination_plan": coordination_plan,
                                "facilitator": "åè°ƒè€…"
                            }
                            
                            with open(json_filepath, 'w', encoding='utf-8') as f:
                                json.dump(coordination_data, f, ensure_ascii=False, indent=2)
                            logger.info(f"ä¿å­˜åè°ƒè€…ç»“æœåˆ°JSONæ–‡ä»¶: {json_filepath}")
                        except Exception as e:
                            logger.error(f"ä¿å­˜åè°ƒè€…ç»“æœJSONæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
                        
                        # æ›´æ–°discussion_stateï¼Œä¿å­˜æ–‡ä»¶è·¯å¾„åˆ°å½“å‰è½®æ¬¡
                        try:
                            current_round_idx = round_number - 1
                            # ç¡®ä¿è½®æ¬¡æ•°æ®å­˜åœ¨
                            while len(discussion_state['rounds']) <= current_round_idx:
                                discussion_state['rounds'].append({
                                    "round_number": len(discussion_state['rounds']) + 1,
                                    "status": "in_progress",
                                    "speeches": [],
                                    "timestamp": datetime.now().isoformat()
                                })
                            
                            round_data = discussion_state['rounds'][current_round_idx]
                            round_data['facilitator_coordination'] = {
                                "md_file": md_filepath,
                                "json_file": json_filepath,
                                "relative_md_file": os.path.relpath(md_filepath, discussion_base_path),
                                "relative_json_file": os.path.relpath(json_filepath, discussion_base_path),
                                "timestamp": timestamp,
                                "datetime": datetime.now().isoformat()
                            }
                            round_data['updated_at'] = datetime.now().isoformat()
                            discussion_state['updated_at'] = datetime.now().isoformat()
                            self._save_discussion_state(discussion_base_path, discussion_state)
                            logger.info(f"å·²æ›´æ–°discussion_state.jsonï¼Œæ·»åŠ åè°ƒè€…ç»“æœæ–‡ä»¶è·¯å¾„åˆ°ç¬¬{round_number}è½®")
                        except Exception as e:
                            logger.error(f"æ›´æ–°discussion_stateå¤±è´¥: {e}", exc_info=True)
                        
                        # åªåœ¨å‰ç«¯æ˜¾ç¤ºæ–‡ä»¶è·¯å¾„
                        abs_md_filepath = os.path.abspath(md_filepath)
                        abs_json_filepath = os.path.abspath(json_filepath)
                        
                        # è®°å½•åè°ƒè€…ç»“æœä¿¡æ¯
                        logger.info(f"ğŸ‘¨â€âš–ï¸ åè°ƒè€…å‘è¨€å®‰æ’å·²ä¿å­˜åˆ°æ–‡ä»¶ï¼š{abs_md_filepath}")
                        
                        # JSONæ–‡ä»¶è·¯å¾„ä¸å‘é€ç»™å‰ç«¯ï¼ˆä¸ç”Ÿæˆchunkï¼‰

                    elif step_type == "speech_start":
                        speaker = step_result.get('speaker', 'æœªçŸ¥')
                        logger.info(f"ğŸ¤ {speaker} å¼€å§‹å‘è¨€")

                    elif step_type == "speech":
                        speaker = step_result.get('speaker', 'æœªçŸ¥')
                        thinking = step_result.get('thinking', '')
                        speech = step_result.get('speech', '')
                        target_expert = step_result.get('target_expert', '')  # è´¨ç–‘è€…é’ˆå¯¹çš„ä¸“å®¶
                        
                        # å¦‚æœ thinking æˆ– speech æ˜¯å­—å…¸ï¼Œæå–å†…å®¹
                        if isinstance(thinking, dict):
                            thinking = thinking.get('raw_response', thinking.get('content', str(thinking)))
                        if isinstance(speech, dict):
                            speech = speech.get('content', str(speech))

                        # åˆ¤æ–­æ˜¯å¦æ˜¯è´¨ç–‘è€…
                        is_skeptic = "skeptic" in speaker.lower()
                        
                        # ç¬¬ä¸€å±‚ï¼šæ¯ä¸ªæ™ºèƒ½ä½“å‘è¨€ä¿å­˜åˆ° discuss/
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        safe_speaker = re.sub(r'[^\w\u4e00-\u9fa5]', '_', speaker)
                        discuss_dir = os.path.join(discussion_base_path, "discuss")
                        os.makedirs(discuss_dir, exist_ok=True)
                        
                        md_filename = f"{safe_speaker}_round{round_number}_{timestamp}.md"
                        md_filepath = os.path.join(discuss_dir, md_filename)
                        
                        json_filename = f"{safe_speaker}_round{round_number}_{timestamp}.json"
                        json_filepath = os.path.join(discuss_dir, json_filename)
                        
                        # æ„å»º Markdown æ–‡ä»¶å†…å®¹
                        if is_skeptic and target_expert:
                            # è´¨ç–‘è€…çš„å‘è¨€æ ¼å¼
                            md_content = f"""# {speaker} çš„è´¨ç–‘

**è½®æ¬¡**: ç¬¬ {round_number} è½®è®¨è®º
**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**é’ˆå¯¹ä¸“å®¶**: {target_expert}

## è´¨ç–‘å†…å®¹

{speech if speech else 'æ— '}
"""
                        else:
                            # æ™®é€šå‘è¨€çš„æ ¼å¼
                            md_content = f"""# {speaker} çš„å‘è¨€

**è½®æ¬¡**: ç¬¬ {round_number} è½®è®¨è®º
**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ€è€ƒè¿‡ç¨‹

{thinking if thinking else 'æ— '}

## å‘è¨€å†…å®¹

{speech if speech else 'æ— '}
"""
                        
                        # æ„å»º JSON æ•°æ®
                        speech_json_data = {
                            "discussion_id": discussion_id,
                            "round_number": round_number,
                            "agent_name": safe_speaker,
                            "speaker": speaker,
                            "thinking": thinking if thinking else '',
                            "speech": speech if speech else '',
                            "target_expert": target_expert if is_skeptic else None,
                            "is_skeptic": is_skeptic,
                            "timestamp": datetime.now().isoformat()
                        }
                        
                        # å†™å…¥ Markdown æ–‡ä»¶
                        try:
                            with open(md_filepath, 'w', encoding='utf-8') as f:
                                f.write(md_content)
                            logger.info(f"ä¿å­˜å‘è¨€åˆ°æ–‡ä»¶: {md_filepath}")
                        except Exception as e:
                            logger.error(f"ä¿å­˜å‘è¨€ Markdown æ–‡ä»¶å¤±è´¥: {e}")
                        
                        # å†™å…¥ JSON æ–‡ä»¶
                        try:
                            with open(json_filepath, 'w', encoding='utf-8') as f:
                                json.dump(speech_json_data, f, ensure_ascii=False, indent=2)
                            logger.info(f"ä¿å­˜å‘è¨€ JSON åˆ°æ–‡ä»¶: {json_filepath}")
                        except Exception as e:
                            logger.error(f"ä¿å­˜å‘è¨€ JSON æ–‡ä»¶å¤±è´¥: {e}")
                        
                        # ä½¿ç”¨ Markdown æ–‡ä»¶è·¯å¾„ä½œä¸ºä¸»å¼•ç”¨
                        filepath = md_filepath

                        # æ›´æ–°discussion_stateï¼Œå°†å‘è¨€ä¿¡æ¯æ·»åŠ åˆ°å½“å‰è½®æ¬¡
                        try:
                            # ç¡®ä¿å½“å‰è½®æ¬¡å­˜åœ¨
                            current_round_idx = round_number - 1
                            while len(discussion_state['rounds']) <= current_round_idx:
                                discussion_state['rounds'].append({
                                    "round_number": len(discussion_state['rounds']) + 1,
                                    "status": "in_progress",
                                    "speeches": [],
                                    "timestamp": datetime.now().isoformat()
                                })
                            
                            # è·å–æˆ–åˆ›å»ºå½“å‰è½®æ¬¡æ•°æ®
                            round_data = discussion_state['rounds'][current_round_idx]
                            if 'speeches' not in round_data:
                                round_data['speeches'] = []
                            
                            # æ·»åŠ å‘è¨€ä¿¡æ¯åˆ°è½®æ¬¡æ•°æ®
                            speech_data = {
                                "speaker": speaker,
                                "thinking": thinking if thinking else '',
                                "speech": speech if speech else '',
                                "file_path": filepath,
                                "json_file_path": json_filepath,
                                "relative_file_path": os.path.relpath(filepath, discussion_base_path),
                                "relative_json_path": os.path.relpath(json_filepath, discussion_base_path),
                                "timestamp": timestamp,
                                "datetime": datetime.now().isoformat(),
                                "is_skeptic": is_skeptic,
                                "target_expert": target_expert if is_skeptic else None
                            }
                            round_data['speeches'].append(speech_data)
                            round_data['round_number'] = round_number
                            round_data['status'] = 'in_progress'
                            round_data['updated_at'] = datetime.now().isoformat()
                            
                            # æ›´æ–°discussion_stateçš„updated_at
                            discussion_state['updated_at'] = datetime.now().isoformat()
                            
                            # ä¿å­˜æ›´æ–°åçš„çŠ¶æ€
                            self._save_discussion_state(discussion_base_path, discussion_state)
                            logger.info(f"å·²æ›´æ–°discussion_state.jsonï¼Œæ·»åŠ {speaker}çš„å‘è¨€åˆ°ç¬¬{round_number}è½®")
                        except Exception as e:
                            logger.error(f"æ›´æ–°discussion_stateå¤±è´¥: {e}", exc_info=True)

                        # è¿”å›æ–‡ä»¶è·¯å¾„é“¾æ¥ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
                        abs_filepath = os.path.abspath(filepath)
                        
                        # è®°å½•æ–‡ä»¶è·¯å¾„ä¿¡æ¯
                        if is_skeptic and target_expert:
                            logger.info(f"ğŸ” {speaker}çš„è´¨ç–‘ï¼ˆé’ˆå¯¹{target_expert}ï¼‰å·²ä¿å­˜åˆ°æ–‡ä»¶ï¼š{abs_filepath}")
                        else:
                            logger.info(f"ğŸ“„ {speaker}çš„å‘è¨€å·²ä¿å­˜åˆ°æ–‡ä»¶ï¼š{abs_filepath}")

                    elif step_type == "speech_end":
                        speaker = step_result.get('speaker', 'æœªçŸ¥')
                        logger.info(f"âœ… {speaker} å‘è¨€ç»“æŸ")

                    elif step_type == "synthesis":
                        content = step_result.get('content', {})
                        synthesis_result = content.get('synthesis_result', '') if isinstance(content, dict) else str(content)
                        if isinstance(synthesis_result, dict):
                            synthesis_result = synthesis_result.get('content', synthesis_result.get('synthesis_report', str(synthesis_result)))
                        
                        # æ›´æ–°discussion_stateï¼Œä¿å­˜ç»¼åˆè€…è§‚ç‚¹
                        try:
                            current_round_idx = round_number - 1
                            if current_round_idx < len(discussion_state['rounds']):
                                round_data = discussion_state['rounds'][current_round_idx]
                                round_data['synthesis'] = {
                                    "content": synthesis_result if isinstance(synthesis_result, str) else str(synthesis_result),
                                    "timestamp": datetime.now().isoformat()
                                }
                                round_data['updated_at'] = datetime.now().isoformat()
                                discussion_state['updated_at'] = datetime.now().isoformat()
                                self._save_discussion_state(discussion_base_path, discussion_state)
                                logger.info(f"å·²ä¿å­˜ç»¼åˆè€…è§‚ç‚¹åˆ°ç¬¬{round_number}è½®")
                        except Exception as e:
                            logger.error(f"ä¿å­˜ç»¼åˆè€…è§‚ç‚¹å¤±è´¥: {e}", exc_info=True)
                        
                        logger.info(f"ğŸ”„ ç»¼åˆè€…æ•´åˆè§‚ç‚¹: {synthesis_result[:200] if isinstance(synthesis_result, str) else str(synthesis_result)[:200]}...")

                    elif step_type == "consensus_update":
                        report = step_result.get('report', {})
                        overall_consensus = report.get('overall_consensus', {})
                        consensus_level = overall_consensus.get('overall_level', 0.0)
                        consensus_desc = overall_consensus.get('analysis', 'æœªåˆ†æ')
                        key_consensus_points = report.get('key_consensus_points', [])
                        key_divergence_points = report.get('key_divergence_points', [])

                        # æ›´æ–°discussion_stateï¼Œä¿å­˜å…±è¯†ä¿¡æ¯
                        try:
                            # æ›´æ–°æ•´ä½“å…±è¯†æ•°æ®
                            discussion_state['consensus_data']['overall_level'] = consensus_level
                            discussion_state['consensus_data']['key_points'] = [
                                cp.get('content', str(cp)) if isinstance(cp, dict) else str(cp) 
                                for cp in key_consensus_points[:10]  # æœ€å¤šä¿å­˜10ä¸ªå…³é”®å…±è¯†ç‚¹
                            ]
                            discussion_state['consensus_data']['divergences'] = [
                                dp.get('content', str(dp)) if isinstance(dp, dict) else str(dp) 
                                for dp in key_divergence_points[:10]  # æœ€å¤šä¿å­˜10ä¸ªåˆ†æ­§ç‚¹
                            ]
                            
                            # æ›´æ–°å½“å‰è½®æ¬¡çš„å…±è¯†ä¿¡æ¯
                            current_round_idx = round_number - 1
                            if current_round_idx < len(discussion_state['rounds']):
                                round_data = discussion_state['rounds'][current_round_idx]
                                round_data['consensus_update'] = {
                                    "consensus_level": consensus_level,
                                    "consensus_analysis": consensus_desc,
                                    "key_consensus_points": [
                                        cp.get('content', str(cp)) if isinstance(cp, dict) else str(cp) 
                                        for cp in key_consensus_points[:5]
                                    ],
                                    "key_divergence_points": [
                                        dp.get('content', str(dp)) if isinstance(dp, dict) else str(dp) 
                                        for dp in key_divergence_points[:5]
                                    ],
                                    "timestamp": datetime.now().isoformat()
                                }
                                round_data['updated_at'] = datetime.now().isoformat()
                            
                            discussion_state['updated_at'] = datetime.now().isoformat()
                            self._save_discussion_state(discussion_base_path, discussion_state)
                            logger.info(f"å·²æ›´æ–°å…±è¯†ä¿¡æ¯åˆ°discussion_state.jsonï¼Œå…±è¯†æ°´å¹³: {consensus_level:.2f}")
                        except Exception as e:
                            logger.error(f"ä¿å­˜å…±è¯†ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)

                        logger.info(f"ğŸ“Š å…±è¯†æ›´æ–° - å…±è¯†æ°´å¹³: {consensus_level:.2f}, å…±è¯†ç‚¹: {len(key_consensus_points)}ä¸ª, åˆ†æ­§ç‚¹: {len(key_divergence_points)}ä¸ª")

                    elif step_type == "round_summary":
                        summary = step_result.get('summary', {})
                        round_summary = summary.get('round_summary', 'æœªç”Ÿæˆæ€»ç»“') if isinstance(summary, dict) else str(summary)

                        # æ›´æ–°discussion_stateï¼Œä¿å­˜è½®æ¬¡æ€»ç»“
                        try:
                            current_round_idx = round_number - 1
                            if current_round_idx < len(discussion_state['rounds']):
                                round_data = discussion_state['rounds'][current_round_idx]
                                round_data['summary'] = {
                                    "content": round_summary if isinstance(round_summary, str) else str(round_summary),
                                    "timestamp": datetime.now().isoformat()
                                }
                        except Exception as e:
                            logger.warning(f"ä¿å­˜è½®æ¬¡æ€»ç»“å¤±è´¥: {e}")

                        # è®°å½•è½®æ¬¡æ€»ç»“
                        logger.info(f"ğŸ“‹ ç¬¬{round_number}è½®è®¨è®ºæ€»ç»“: {round_summary[:200] if isinstance(round_summary, str) else str(round_summary)[:200]}...")

                    elif step_type == "exception_report":
                        exception_report = step_result.get('report', '')
                        logger.info(f"æ”¶åˆ°å¼‚å¸¸æŠ¥å‘Š: {exception_report}")

                        # è®°å½•å¼‚å¸¸æŠ¥å‘Šchunk
                        logger.info(f"å¼‚å¸¸æŠ¥å‘Š: {exception_report}")

                        # å¦‚æœæœ‰ä¸¥é‡å¼‚å¸¸ï¼Œæ·»åŠ è­¦å‘Šä¿¡æ¯
                        if "éœ€è¦äººå·¥å¹²é¢„" in exception_report:
                            logger.warning("âš ï¸ ç³»ç»Ÿæ£€æµ‹åˆ°éœ€è¦äººå·¥å¹²é¢„çš„å¼‚å¸¸ï¼Œè¯·åŠæ—¶å¤„ç†ä»¥ç¡®ä¿è®¨è®ºè´¨é‡ã€‚")
                        summary = step_result.get('summary', {})
                        round_summary = summary.get('round_summary', 'æœªç”Ÿæˆæ€»ç»“') if isinstance(summary, dict) else str(summary)

                        # æ›´æ–°discussion_stateï¼Œä¿å­˜è½®æ¬¡æ€»ç»“
                        try:
                            current_round_idx = round_number - 1
                            if current_round_idx < len(discussion_state['rounds']):
                                round_data = discussion_state['rounds'][current_round_idx]
                                round_data['summary'] = {
                                    "content": round_summary if isinstance(round_summary, str) else str(round_summary),
                                    "timestamp": datetime.now().isoformat()
                                }
                                round_data['updated_at'] = datetime.now().isoformat()
                                discussion_state['updated_at'] = datetime.now().isoformat()
                                self._save_discussion_state(discussion_base_path, discussion_state)
                                logger.info(f"å·²ä¿å­˜ç¬¬{round_number}è½®æ€»ç»“åˆ°discussion_state.json")
                        except Exception as e:
                            logger.error(f"ä¿å­˜è½®æ¬¡æ€»ç»“å¤±è´¥: {e}", exc_info=True)
                        
                        logger.info(f"ğŸ“‹ æœ¬è½®æ€»ç»“: {round_summary[:200] if isinstance(round_summary, str) else str(round_summary)[:200]}...")

                    elif step_type == "user_decision":
                        consensus_level = step_result.get('consensus_level', 0.0)
                        options = step_result.get('options', [])

                        # æ›´æ–°æœ¬è½®çŠ¶æ€ï¼ˆä¿ç•™å·²æœ‰çš„å‘è¨€è®°å½•ï¼‰
                        try:
                            current_round_idx = round_number - 1
                            # ç¡®ä¿è½®æ¬¡æ•°æ®å­˜åœ¨
                            while len(discussion_state['rounds']) <= current_round_idx:
                                discussion_state['rounds'].append({
                                    "round_number": len(discussion_state['rounds']) + 1,
                                    "status": "in_progress",
                                    "speeches": [],
                                    "timestamp": datetime.now().isoformat()
                                })
                            
                            # è·å–å½“å‰è½®æ¬¡æ•°æ®ï¼ˆä¿ç•™å·²æœ‰çš„speechesï¼‰
                            round_data = discussion_state['rounds'][current_round_idx]
                            round_data['round_number'] = round_number
                            round_data['status'] = 'completed'
                            round_data['consensus_level'] = consensus_level
                            round_data['completed_at'] = datetime.now().isoformat()
                            round_data['updated_at'] = datetime.now().isoformat()
                            
                            # å¦‚æœspeechesä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
                            if 'speeches' not in round_data:
                                round_data['speeches'] = []
                            
                            logger.info(f"ç¬¬{round_number}è½®å®Œæˆï¼Œå…±{len(round_data['speeches'])}æ¡å‘è¨€è®°å½•")
                        except Exception as e:
                            logger.error(f"æ›´æ–°è½®æ¬¡çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
                            # å¦‚æœå‡ºé”™ï¼Œåˆ›å»ºæ–°çš„è½®æ¬¡æ•°æ®
                            round_data = {
                                "round_number": round_number,
                                "status": "completed",
                                "consensus_level": consensus_level,
                                "speeches": [],
                                "timestamp": datetime.now().isoformat()
                            }
                            discussion_state['rounds'].append(round_data)
                        
                        # æ›´æ–°æ•´ä½“çŠ¶æ€ - ä¸€è½®å®Œæˆï¼ŒçŠ¶æ€æ”¹ä¸º pausedï¼ˆç­‰å¾…ç”¨æˆ·å†³ç­–ï¼‰
                        discussion_state['current_round'] = round_number
                        discussion_state['consensus_data']['overall_level'] = consensus_level
                        discussion_state['status'] = 'paused'  # ä¸€è½®å®Œæˆï¼Œç­‰å¾…ç”¨æˆ·å†³ç­–
                        discussion_state['updated_at'] = datetime.now().isoformat()
                        # ç¡®ä¿çŠ¶æ€è¢«ä¿å­˜
                        try:
                            self._save_discussion_state(discussion_base_path, discussion_state)
                            logger.info(f"ç¬¬{round_number}è½®å®Œæˆï¼ŒçŠ¶æ€å·²æ›´æ–°ä¸º paused")
                        except Exception as save_error:
                            logger.error(f"ä¿å­˜è®¨è®ºçŠ¶æ€å¤±è´¥: {save_error}", exc_info=True)

                        # è®°å½•æœ¬è½®å®Œæˆä¿¡æ¯
                        logger.info(f"âœ… ç¬¬ {round_number} è½®è®¨è®ºå®Œæˆï¼Œå…±è¯†æ°´å¹³: {consensus_level:.2f}")
                        
                        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å…±è¯†é˜ˆå€¼
                        if consensus_level >= 0.8:
                            logger.info(f"ğŸ‰ è¾¾åˆ°è¾ƒé«˜å…±è¯†æ°´å¹³ ({consensus_level:.2f})ï¼Œç»“æŸè®¨è®º")
                            break  # è¾¾åˆ°å…±è¯†ï¼Œè·³å‡ºå¾ªç¯
                        else:
                            # æœªè¾¾åˆ°å…±è¯†ï¼Œç»§ç»­ä¸‹ä¸€è½®è®¨è®º
                            logger.info(f"ğŸ”„ å…±è¯†æ°´å¹³æœªè¾¾æ ‡ ({consensus_level:.2f} < 0.8)ï¼Œç»§ç»­ç¬¬ {round_number + 1} è½®è®¨è®º")
                            round_number += 1
                            continue  # ç»§ç»­ä¸‹ä¸€è½®

                # å¦‚æœæœ¬è½®æ²¡æœ‰å‘è¨€ï¼Œè®°å½•è­¦å‘Š
                if not has_speeches:
                    logger.warning(f"âš ï¸ ç¬¬ {round_number} è½®è®¨è®ºæ²¡æœ‰äº§ç”Ÿä»»ä½•å‘è¨€ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜ã€‚")
                    # å³ä½¿æ²¡æœ‰å‘è¨€ï¼Œä¹Ÿæ ‡è®°ä¸ºå®Œæˆå¹¶ç»§ç»­ä¸‹ä¸€è½®
                    try:
                        current_round_idx = round_number - 1
                        while len(discussion_state['rounds']) <= current_round_idx:
                            discussion_state['rounds'].append({
                                "round_number": len(discussion_state['rounds']) + 1,
                                "status": "completed",
                                "speeches": [],
                                "timestamp": datetime.now().isoformat()
                            })
                        round_data = discussion_state['rounds'][current_round_idx]
                        round_data['round_number'] = round_number
                        round_data['status'] = 'completed'
                        round_data['completed_at'] = datetime.now().isoformat()
                        discussion_state['current_round'] = round_number
                        discussion_state['status'] = 'active'  # ä¿æŒæ´»è·ƒçŠ¶æ€ï¼Œç»§ç»­è®¨è®º
                        discussion_state['updated_at'] = datetime.now().isoformat()
                        self._save_discussion_state(discussion_base_path, discussion_state)
                        logger.info(f"ç¬¬{round_number}è½®å®Œæˆï¼ˆæ— å‘è¨€ï¼‰ï¼Œç»§ç»­ä¸‹ä¸€è½®")
                    except Exception as e:
                        logger.error(f"æ›´æ–°è½®æ¬¡çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
                    
                    logger.info(f"ğŸ”„ ç¬¬ {round_number} è½®è®¨è®ºå®Œæˆï¼ˆæ— å‘è¨€ï¼‰ï¼Œç»§ç»­ç¬¬ {round_number + 1} è½®")
                    round_number += 1
                    continue  # ç»§ç»­ä¸‹ä¸€è½®

                # å¦‚æœæœ¬è½®æ­£å¸¸å®Œæˆä½†æ²¡æœ‰ user_decision æ­¥éª¤
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å…±è¯†é˜ˆå€¼
                try:
                    status = discussion_system.get_discussion_status()
                    consensus_level = status.get('consensus_level', 0.0) if isinstance(status, dict) else 0.0
                    
                    # æ›´æ–°å½“å‰è½®æ¬¡çŠ¶æ€
                    try:
                        current_round_idx = round_number - 1
                        if current_round_idx < len(discussion_state['rounds']):
                            round_data = discussion_state['rounds'][current_round_idx]
                            round_data['status'] = 'completed'
                            round_data['completed_at'] = datetime.now().isoformat()
                            discussion_state['current_round'] = round_number
                            discussion_state['consensus_data']['overall_level'] = consensus_level
                            discussion_state['updated_at'] = datetime.now().isoformat()
                            self._save_discussion_state(discussion_base_path, discussion_state)
                    except Exception as e:
                        logger.error(f"æ›´æ–°è½®æ¬¡çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
                    
                    if consensus_level >= 0.8:
                        logger.info(f"ğŸ‰ ç¬¬ {round_number} è½®è®¨è®ºå®Œæˆï¼Œè¾¾åˆ°è¾ƒé«˜å…±è¯†æ°´å¹³ ({consensus_level:.2f})ï¼Œç»“æŸè®¨è®º")
                        break  # è¾¾åˆ°å…±è¯†ï¼Œè·³å‡ºå¾ªç¯
                    else:
                        # æœªè¾¾åˆ°å…±è¯†ï¼Œç»§ç»­ä¸‹ä¸€è½®è®¨è®º
                        logger.info(f"ğŸ”„ ç¬¬ {round_number} è½®è®¨è®ºå®Œæˆï¼Œå…±è¯†æ°´å¹³: {consensus_level:.2f}ï¼Œç»§ç»­ç¬¬ {round_number + 1} è½®")
                        round_number += 1
                        continue  # ç»§ç»­ä¸‹ä¸€è½®
                except Exception as e:
                    logger.warning(f"è·å–è®¨è®ºçŠ¶æ€å¤±è´¥: {str(e)}")
                    # è·å–çŠ¶æ€å¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€è½®
                    try:
                        current_round_idx = round_number - 1
                        if current_round_idx < len(discussion_state['rounds']):
                            round_data = discussion_state['rounds'][current_round_idx]
                            round_data['status'] = 'completed'
                            round_data['completed_at'] = datetime.now().isoformat()
                        discussion_state['current_round'] = round_number
                        discussion_state['status'] = 'active'
                        self._save_discussion_state(discussion_base_path, discussion_state)
                    except Exception as update_error:
                        logger.error(f"æ›´æ–°è½®æ¬¡çŠ¶æ€å¤±è´¥: {update_error}", exc_info=True)
                    
                    logger.info(f"ğŸ”„ ç¬¬ {round_number} è½®è®¨è®ºå®Œæˆï¼Œç»§ç»­ç¬¬ {round_number + 1} è½®")
                    round_number += 1
                    continue  # ç»§ç»­ä¸‹ä¸€è½®

            # å¦‚æœå¾ªç¯æ­£å¸¸ç»“æŸï¼ˆè¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼‰ï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            try:
                logger.info("ğŸ“„ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆè®¨è®ºæŠ¥å‘Š...")

                final_report = discussion_system.generate_final_report()
                
                if final_report:
                    consensus_report = final_report.get('consensus_report', {})
                    overall_consensus = consensus_report.get('overall_consensus', {}) if isinstance(consensus_report, dict) else {}
                    consensus_level = overall_consensus.get('overall_level', 0.0) if isinstance(overall_consensus, dict) else 0.0
                    consensus_analysis = overall_consensus.get('analysis', 'æœªåˆ†æ') if isinstance(overall_consensus, dict) else 'æœªåˆ†æ'
                    
                    logger.info(f"ğŸ­ åœ†æ¡Œè®¨è®ºæœ€ç»ˆæŠ¥å‘Š - è®¨è®ºä¸»é¢˜: {final_report.get('discussion_topic', 'æœªæŒ‡å®š')}, æ€»è½®æ¬¡: {final_report.get('total_rounds', 0)}, æœ€ç»ˆå…±è¯†æ°´å¹³: {consensus_level:.2f}")
                    
                    # æ›´æ–°ä¼šè®®çŠ¶æ€ä¸ºå®Œæˆ
                    discussion_state['status'] = 'completed'
                    discussion_state['consensus_data']['overall_level'] = consensus_level
                    discussion_state['final_report'] = {
                        'total_rounds': final_report.get('total_rounds', 0),
                        'consensus_level': consensus_level,
                        'key_insights': final_report.get('key_insights', []),
                        'action_recommendations': final_report.get('action_recommendations', [])
                    }
                    self._save_discussion_state(discussion_base_path, discussion_state)
                    
                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å®Œæˆ
                    if session_id and discussion_id:
                        try:
                            cSingleSqlite.update_discussion_task_status(
                                session_id=session_id,
                                discussion_id=discussion_id,
                                task_status='completed'
                            )
                            logger.info(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å®Œæˆ: session_id={session_id}, discussion_id={discussion_id}")
                        except Exception as e:
                            logger.warning(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
                else:
                    logger.warning("âš ï¸ æ— æ³•ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
            except Exception as e:
                logger.error(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {str(e)}", exc_info=True)
                logger.warning(f"âš ï¸ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}")

            logger.info("âœ… ç¬¬ä¸€å±‚ï¼šåœ†æ¡Œè®¨è®ºå®Œæˆï¼")
            
            # ==================================================
            # ç”Ÿæˆç¬¬ä¸€å±‚æ±‡æ€»æ–‡æ¡£ï¼ˆå¸¦ç›®å½•ç´¢å¼•ï¼Œä¾›ç¬¬äºŒå±‚ä½¿ç”¨ï¼‰
            # ==================================================
            try:
                final_report_for_summary = final_report if 'final_report' in locals() and final_report else {}
                summary_path = self._generate_layer1_summary_document(
                    discussion_base_path, discussion_state, final_report_for_summary, query
                )
                if summary_path:
                    logger.info(f"ğŸ“š ç¬¬ä¸€å±‚æ±‡æ€»æ–‡æ¡£å·²ç”Ÿæˆ: {summary_path}")
                    self._save_discussion_state(discussion_base_path, discussion_state)
                else:
                    logger.warning("âš ï¸ ç¬¬ä¸€å±‚æ±‡æ€»æ–‡æ¡£ç”Ÿæˆå¤±è´¥")
            except Exception as summary_error:
                logger.error(f"ç”Ÿæˆç¬¬ä¸€å±‚æ±‡æ€»æ–‡æ¡£å¼‚å¸¸: {summary_error}")
            
            # ==================================================
            # ç¬¬äºŒå±‚: å®æ–½è®¨è®ºç»„ï¼ˆé‡å¤å¯åŠ¨æ—¶è‹¥å·²å®Œæˆåˆ™è·³è¿‡ï¼›æ™ºèƒ½ä½“ä¸å‘è¨€çŠ¶æ€è§ discussion_state['layer2']/implementation_layerï¼‰
            # ==================================================
            try:
                impl_done = (discussion_state.get("implementation_layer") or {}).get("status") == "completed"
                conc_done = (discussion_state.get("concretization_layer") or {}).get("status") == "completed"

                if impl_done:
                    logger.info("ğŸ”„ ç¬¬äºŒå±‚å·²åœ¨æœ¬ä»»åŠ¡ä¸­å®Œæˆï¼Œè·³è¿‡å®æ–½è®¨è®ºç»„ï¼ˆå¯å¤ç”¨ discussion_state['layer2'] ä¸ roles ä¸‹ layer_2_* æ™ºèƒ½ä½“ï¼‰")

                if conc_done:
                    logger.info("ğŸ”„ ç¬¬ä¸‰å±‚å…·åƒåŒ–å·²åœ¨æœ¬ä»»åŠ¡ä¸­å®Œæˆï¼Œè·³è¿‡å…·åƒåŒ–å±‚")

                # å°†ç¬¬ä¸€å±‚ç»“æœè½¬æ¢ä¸º DecisionOutput
                decision_output = self._convert_to_decision_output(
                    discussion_state,
                    final_report if 'final_report' in locals() and final_report else {},
                    query
                )

                # åªæœ‰å½“æœ‰ä»»åŠ¡ä¸”ç¬¬äºŒå±‚æœªå®Œæˆæ—¶æ‰è¿è¡Œç¬¬äºŒå±‚
                if decision_output.tasks and not impl_done:
                    logger.info(f"\nğŸ“¦ å†³ç­–å±‚è¾“å‡º: {len(decision_output.tasks)} ä¸ªä»»åŠ¡, {len(decision_output.objectives)} ä¸ªç›®æ ‡")

                    impl_outputs, impl_result = self._run_implementation_layer(
                        decision_output,
                        discussion_state,
                        discussion_base_path
                    )
                elif decision_output.tasks and impl_done:
                    impl_outputs, impl_result = [], None

                # ç¬¬ä¸‰å±‚ï¼šä»…åœ¨æœ¬å±‚æœªå®Œæˆæ—¶è¿è¡Œï¼ˆä¾èµ– implement/ï¼Œç¬¬äºŒå±‚è·³è¿‡æ—¶ä»å¯æ‰§è¡Œï¼‰
                if (decision_output.tasks and not conc_done):
                    self._run_concretization_layer(
                        discussion_base_path,
                        discussion_state.get("discussion_id", ""),
                    )
                    discussion_state["concretization_layer"] = {
                        "status": "completed",
                        "timestamp": datetime.now().isoformat(),
                    }
                    self._save_discussion_state(discussion_base_path, discussion_state)
                elif not decision_output.tasks:
                    logger.info("âš ï¸ æ²¡æœ‰å¯æ‰§è¡Œä»»åŠ¡ï¼Œè·³è¿‡å®æ–½å±‚ä¸å…·åƒåŒ–å±‚")
                    
            except Exception as layer_error:
                logger.error(f"âŒ ç¬¬äºŒå±‚æ‰§è¡Œå¤±è´¥: {layer_error}", exc_info=True)
                discussion_state['layer_error'] = {
                    'message': str(layer_error),
                    'timestamp': datetime.now().isoformat()
                }
                self._save_discussion_state(discussion_base_path, discussion_state)
            
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ‰ ä¸‰å±‚è®¨è®ºç³»ç»Ÿå…¨éƒ¨å®Œæˆï¼ˆè®¨è®ºå±‚ â†’ å®æ–½å±‚ â†’ å…·åƒåŒ–å±‚ï¼‰ï¼")
            logger.info("=" * 60)
            try:
                self._build_speech_search_index(discussion_base_path)
            except Exception as idx_err:
                logger.warning(f"å‘è¨€æ£€ç´¢ç´¢å¼•æ„å»ºå¤±è´¥: {idx_err}")
            return True

        except Exception as e:
            logger.error(f"Error in chat_with_discussion: {str(e)}")
            import traceback
            error_traceback = traceback.format_exc()
            _id = f"roundtable-error-{int(time.time())}"
            
            # æ›´æ–°ä¼šè®®çŠ¶æ€ä¸ºé”™è¯¯
            try:
                if 'discussion_state' in locals() and 'discussion_base_path' in locals():
                    discussion_state['status'] = 'error'
                    discussion_state['error'] = {
                        'message': str(e),
                        'traceback': error_traceback,
                        'timestamp': datetime.now().isoformat()
                    }
                    self._save_discussion_state(discussion_base_path, discussion_state)
            except Exception as save_error:
                logger.error(f"ä¿å­˜é”™è¯¯çŠ¶æ€å¤±è´¥: {save_error}")
            
            logger.error(f"âŒ åœ†æ¡Œè®¨è®ºç³»ç»Ÿé”™è¯¯: {str(e)}")
            return False

   